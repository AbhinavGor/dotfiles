INFO: 2022-12-07 21:43:53,989: main() 'Using profile folder /home/abhinavgorantla/.config/variety/'
INFO: 2022-12-07 21:43:53,993: perform_upgrade() 'Last run version was 0.8.3 or earlier, current version is 0.8.3'
INFO: 2022-12-07 21:43:54,115: process_command() 'Received command: ['--profile', '/home/abhinavgorantla/.config/variety/']'
INFO: 2022-12-07 21:43:54,118: load_banned() 'Missing or invalid banned URLs list, no URLs will be banned'
INFO: 2022-12-07 21:43:54,128: start() 'Using data_path /usr/share/variety'
INFO: 2022-12-07 21:43:54,128: load() 'Jumble loading'
INFO: 2022-12-07 21:43:54,129: _walk_modules() 'Jumble loading module in __init__ from /usr/lib/python3/dist-packages/variety/plugins/builtin/__init__.py'
INFO: 2022-12-07 21:43:54,130: _walk_modules() 'Jumble loading module in UrbanDictionarySource from /usr/lib/python3/dist-packages/variety/plugins/builtin/quotes/UrbanDictionarySource.py'
INFO: 2022-12-07 21:43:54,131: load() 'Jumble found plugin class: <class 'UrbanDictionarySource.UrbanDictionarySource'>: {'name': 'Urban Dictionary', 'description': 'Displays definitions from Urban Dictionary', 'author': 'James Miller', 'version': '0.1'}'
INFO: 2022-12-07 21:43:54,131: _walk_modules() 'Jumble loading module in GoodreadsSource from /usr/lib/python3/dist-packages/variety/plugins/builtin/quotes/GoodreadsSource.py'
INFO: 2022-12-07 21:43:54,138: load() 'Jumble found plugin class: <class 'GoodreadsSource.GoodreadsSource'>: {'name': 'Goodreads', 'description': 'Fetches quotes from Goodreads.com', 'author': 'Peter Levi', 'version': '0.1'}'
INFO: 2022-12-07 21:43:54,139: _walk_modules() 'Jumble loading module in FortuneSource from /usr/lib/python3/dist-packages/variety/plugins/builtin/quotes/FortuneSource.py'
INFO: 2022-12-07 21:43:54,139: load() 'Jumble found plugin class: <class 'FortuneSource.FortuneSource'>: {'name': 'UNIX fortune program', 'description': 'Displays quotes using the UNIX fortune program. You may want to install additional fortune packs, e.g. fortunes-bofh-excuses.', 'author': 'Dan Jones', 'version': '0.1'}'
INFO: 2022-12-07 21:43:54,140: _walk_modules() 'Jumble loading module in QuotationsPageSource from /usr/lib/python3/dist-packages/variety/plugins/builtin/quotes/QuotationsPageSource.py'
INFO: 2022-12-07 21:43:54,140: load() 'Jumble found plugin class: <class 'QuotationsPageSource.QuotationsPageSource'>: {'name': 'TheQuotationsPage.com', 'description': 'Fetches quotes from TheQuotationsPage.com', 'author': 'Peter Levi', 'version': '0.1'}'
INFO: 2022-12-07 21:43:54,141: _walk_modules() 'Jumble loading module in __init__ from /usr/lib/python3/dist-packages/variety/plugins/builtin/quotes/__init__.py'
INFO: 2022-12-07 21:43:54,141: _walk_modules() 'Jumble loading module in LocalFilesSource from /usr/lib/python3/dist-packages/variety/plugins/builtin/quotes/LocalFilesSource.py'
INFO: 2022-12-07 21:43:54,142: load() 'Jumble found plugin class: <class 'LocalFilesSource.LocalFilesSource'>: {'name': 'Local text files', 'description': 'Displays quotes, defined in local text files.\nPut your own txt files in: /home/abhinavgorantla/.config/variety/pluginconfig/quotes/.\nThe file format is:\n\nquote -- author\n.\nsecond quote -- another author\n.\netc...\n\nExample: http://rvelthuis.de/zips/quotes.txt', 'author': 'Peter Levi', 'version': '0.1'}'
INFO: 2022-12-07 21:43:54,142: _walk_modules() 'Jumble loading module in WallhavenDownloader from /usr/lib/python3/dist-packages/variety/plugins/builtin/downloaders/WallhavenDownloader.py'
INFO: 2022-12-07 21:43:54,144: _walk_modules() 'Jumble loading module in EarthviewDownloader from /usr/lib/python3/dist-packages/variety/plugins/builtin/downloaders/EarthviewDownloader.py'
INFO: 2022-12-07 21:43:54,145: load() 'Jumble found plugin class: <class 'EarthviewDownloader.EarthviewDownloader'>: {'name': 'EarthviewDownloader', 'description': 'Google Earth View Wallpapers', 'author': 'Peter Levi', 'version': '0.1'}'
INFO: 2022-12-07 21:43:54,145: _walk_modules() 'Jumble loading module in BingDownloader from /usr/lib/python3/dist-packages/variety/plugins/builtin/downloaders/BingDownloader.py'
INFO: 2022-12-07 21:43:54,146: load() 'Jumble found plugin class: <class 'BingDownloader.BingDownloader'>: {'name': 'BingDownloader', 'description': 'Bing Photo of the Day', 'author': 'Peter Levi', 'version': '0.1'}'
INFO: 2022-12-07 21:43:54,146: _walk_modules() 'Jumble loading module in UnsplashDownloader from /usr/lib/python3/dist-packages/variety/plugins/builtin/downloaders/UnsplashDownloader.py'
INFO: 2022-12-07 21:43:54,147: load() 'Jumble found plugin class: <class 'UnsplashDownloader.UnsplashDownloader'>: {'name': 'UnsplashDownloader', 'description': 'High-resolution photos from Unsplash.com', 'author': 'Peter Levi', 'version': '0.1'}'
INFO: 2022-12-07 21:43:54,147: _walk_modules() 'Jumble loading module in APODDownloader from /usr/lib/python3/dist-packages/variety/plugins/builtin/downloaders/APODDownloader.py'
INFO: 2022-12-07 21:43:54,148: load() 'Jumble found plugin class: <class 'APODDownloader.APODDownloader'>: {'name': 'APODDownloader', 'description': 'NASA Astro Pic of the Day', 'author': 'Peter Levi', 'version': '0.1'}'
INFO: 2022-12-07 21:43:54,148: _walk_modules() 'Jumble loading module in MediaRSSSource from /usr/lib/python3/dist-packages/variety/plugins/builtin/downloaders/MediaRSSSource.py'
INFO: 2022-12-07 21:43:54,150: load() 'Jumble found plugin class: <class 'MediaRSSSource.MediaRSSSource'>: {'name': 'MediaRSSSource', 'description': 'Configurable source for fetching images from MediaRSS feeds', 'author': 'Peter Levi', 'version': '0.1'}'
INFO: 2022-12-07 21:43:54,151: _walk_modules() 'Jumble loading module in WallhavenSource from /usr/lib/python3/dist-packages/variety/plugins/builtin/downloaders/WallhavenSource.py'
INFO: 2022-12-07 21:43:54,151: load() 'Jumble found plugin class: <class 'WallhavenSource.WallhavenSource'>: {'name': 'MediaRSSSource', 'description': 'Configurable source for fetching images from Wallhaven.cc', 'author': 'Peter Levi', 'version': '0.1'}'
INFO: 2022-12-07 21:43:54,152: _walk_modules() 'Jumble loading module in DesktopprDownloader from /usr/lib/python3/dist-packages/variety/plugins/builtin/downloaders/DesktopprDownloader.py'
INFO: 2022-12-07 21:43:54,152: load() 'Jumble found plugin class: <class 'DesktopprDownloader.DesktopprDownloader'>: {'name': 'DesktopprDownloader', 'description': 'Random wallpapers from Desktoppr.co', 'author': 'Peter Levi', 'version': '0.1'}'
INFO: 2022-12-07 21:43:54,153: _walk_modules() 'Jumble loading module in MediaRSSDownloader from /usr/lib/python3/dist-packages/variety/plugins/builtin/downloaders/MediaRSSDownloader.py'
INFO: 2022-12-07 21:43:54,153: _walk_modules() 'Jumble loading module in RedditSource from /usr/lib/python3/dist-packages/variety/plugins/builtin/downloaders/RedditSource.py'
INFO: 2022-12-07 21:43:54,154: load() 'Jumble found plugin class: <class 'RedditSource.RedditSource'>: {'name': 'RedditSource', 'description': 'Configurable source for fetching images from Reddit', 'author': 'Peter Levi', 'version': '0.1'}'
INFO: 2022-12-07 21:43:54,155: _walk_modules() 'Jumble loading module in __init__ from /usr/lib/python3/dist-packages/variety/plugins/builtin/downloaders/__init__.py'
INFO: 2022-12-07 21:43:54,155: _walk_modules() 'Jumble loading module in UnsplashConfigurableSource from /usr/lib/python3/dist-packages/variety/plugins/builtin/downloaders/UnsplashConfigurableSource.py'
INFO: 2022-12-07 21:43:54,156: load() 'Jumble found plugin class: <class 'UnsplashConfigurableSource.UnsplashConfigurableSource'>: {'name': 'UnsplashConfigurableSource', 'description': 'Configurable source for fetching photos from Unsplash.com', 'author': 'Peter Levi', 'version': '0.1'}'
INFO: 2022-12-07 21:43:54,157: _walk_modules() 'Jumble loading module in RedditDownloader from /usr/lib/python3/dist-packages/variety/plugins/builtin/downloaders/RedditDownloader.py'
INFO: 2022-12-07 21:43:54,158: _walk_modules() 'Jumble loading module in ChromeOSWallpapersDownloader from /usr/lib/python3/dist-packages/variety/plugins/builtin/downloaders/ChromeOSWallpapersDownloader.py'
INFO: 2022-12-07 21:43:54,158: load() 'Jumble found plugin class: <class 'ChromeOSWallpapersDownloader.ChromeOSWallpapersDownloader'>: {'name': 'ChromeOsWallpapersDownloader', 'description': 'Chrome OS Wallpapers', 'author': 'Peter Levi', 'version': '0.1'}'
INFO: 2022-12-07 21:43:54,162: reload_config() 'Creating new downloader for type flickr, location user:www.flickr.com/photos/peter-levi/;user_id:93647178@N00;'
INFO: 2022-12-07 21:43:54,162: reload_config() 'Creating new downloader for type apod, location NASA Astro Pic of the Day'
INFO: 2022-12-07 21:43:54,162: reload_config() 'Creating new downloader for type bing, location Bing Photo of the Day'
INFO: 2022-12-07 21:43:54,162: reload_config() 'Creating new downloader for type chromeos, location Chrome OS Wallpapers'
INFO: 2022-12-07 21:43:54,162: reload_config() 'Creating new downloader for type desktoppr, location Random wallpapers from Desktoppr.co'
INFO: 2022-12-07 21:43:54,162: reload_config() 'Creating new downloader for type earthview, location Google Earth View Wallpapers'
INFO: 2022-12-07 21:43:54,162: reload_config() 'Creating new downloader for type unsplash, location High-resolution photos from Unsplash.com'
INFO: 2022-12-07 21:43:54,164: log_options() 'Loaded options:'
INFO: 2022-12-07 21:43:54,165: log_options() 'change_enabled = True'
INFO: 2022-12-07 21:43:54,165: log_options() 'change_interval = 300'
INFO: 2022-12-07 21:43:54,165: log_options() 'change_on_start = False'
INFO: 2022-12-07 21:43:54,165: log_options() 'clipboard_enabled = False'
INFO: 2022-12-07 21:43:54,165: log_options() 'clipboard_hosts = ['wallhaven.cc', 'wallpapers.net', 'flickr.com', 'imgur.com', 'deviantart.com', 'interfacelift.com', 'vladstudio.com', 'imageshack.us', 'deviantart.net', 'imageshack.com']'
INFO: 2022-12-07 21:43:54,165: log_options() 'clipboard_use_whitelist = True'
INFO: 2022-12-07 21:43:54,165: log_options() 'clock_date_font = Ubuntu Condensed, 30'
INFO: 2022-12-07 21:43:54,165: log_options() 'clock_enabled = False'
INFO: 2022-12-07 21:43:54,165: log_options() 'clock_filter = -density 100 -font `fc-match -f '%{file[0]}' '%CLOCK_FONT_NAME'` -pointsize %CLOCK_FONT_SIZE -gravity SouthEast -fill '#00000044' -annotate 0x0+[%HOFFSET+58]+[%VOFFSET+108] '%H:%M' -fill white -annotate 0x0+[%HOFFSET+60]+[%VOFFSET+110] '%H:%M' -font `fc-match -f '%{file[0]}' '%DATE_FONT_NAME'` -pointsize %DATE_FONT_SIZE -fill '#00000044' -annotate 0x0+[%HOFFSET+58]+[%VOFFSET+58] '%A, %B %d' -fill white -annotate 0x0+[%HOFFSET+60]+[%VOFFSET+60] '%A, %B %d''
INFO: 2022-12-07 21:43:54,165: log_options() 'clock_font = Ubuntu Condensed, 70'
INFO: 2022-12-07 21:43:54,165: log_options() 'configfile = /home/abhinavgorantla/.config/variety/variety.conf'
INFO: 2022-12-07 21:43:54,165: log_options() 'copyto_enabled = False'
INFO: 2022-12-07 21:43:54,165: log_options() 'copyto_folder = Default'
INFO: 2022-12-07 21:43:54,165: log_options() 'desired_color = None'
INFO: 2022-12-07 21:43:54,165: log_options() 'desired_color_enabled = False'
INFO: 2022-12-07 21:43:54,165: log_options() 'download_folder = /home/abhinavgorantla/.config/variety/Downloaded'
INFO: 2022-12-07 21:43:54,165: log_options() 'download_preference_ratio = 0.9'
INFO: 2022-12-07 21:43:54,165: log_options() 'favorites_folder = /home/abhinavgorantla/.config/variety/Favorites'
INFO: 2022-12-07 21:43:54,165: log_options() 'favorites_operations = [['Downloaded', 'Copy'], ['Fetched', 'Move'], ['Others', 'Copy']]'
INFO: 2022-12-07 21:43:54,165: log_options() 'fetched_folder = /home/abhinavgorantla/.config/variety/Fetched'
INFO: 2022-12-07 21:43:54,165: log_options() 'filters = [[False, 'Keep original', ''], [False, 'Grayscale', '-type Grayscale'], [False, 'Heavy blur', '-blur 120x40'], [False, 'Soft blur', '-blur 20x7'], [False, 'Oil painting', '-paint 8'], [False, 'Pointilism', '-spread 10 -noise 3'], [False, 'Pixellate', '-scale 3% -scale 3333%']]'
INFO: 2022-12-07 21:43:54,165: log_options() 'icon = Light'
INFO: 2022-12-07 21:43:54,165: log_options() 'lightness_enabled = False'
INFO: 2022-12-07 21:43:54,165: log_options() 'lightness_mode = 0'
INFO: 2022-12-07 21:43:54,165: log_options() 'min_rating = 4'
INFO: 2022-12-07 21:43:54,165: log_options() 'min_rating_enabled = False'
INFO: 2022-12-07 21:43:54,165: log_options() 'min_size = 80'
INFO: 2022-12-07 21:43:54,165: log_options() 'min_size_enabled = False'
INFO: 2022-12-07 21:43:54,165: log_options() 'quota_enabled = True'
INFO: 2022-12-07 21:43:54,165: log_options() 'quota_size = 1000'
INFO: 2022-12-07 21:43:54,165: log_options() 'quotes_authors = '
INFO: 2022-12-07 21:43:54,165: log_options() 'quotes_bg_color = [80, 80, 80]'
INFO: 2022-12-07 21:43:54,165: log_options() 'quotes_bg_opacity = 55'
INFO: 2022-12-07 21:43:54,166: log_options() 'quotes_change_enabled = False'
INFO: 2022-12-07 21:43:54,166: log_options() 'quotes_change_interval = 300'
INFO: 2022-12-07 21:43:54,166: log_options() 'quotes_disabled_sources = ['Urban Dictionary']'
INFO: 2022-12-07 21:43:54,166: log_options() 'quotes_enabled = False'
INFO: 2022-12-07 21:43:54,166: log_options() 'quotes_favorites_file = /home/abhinavgorantla/.config/variety/favorite_quotes.txt'
INFO: 2022-12-07 21:43:54,166: log_options() 'quotes_font = Bitstream Charter 30'
INFO: 2022-12-07 21:43:54,166: log_options() 'quotes_hpos = 100'
INFO: 2022-12-07 21:43:54,166: log_options() 'quotes_max_length = 250'
INFO: 2022-12-07 21:43:54,166: log_options() 'quotes_tags = '
INFO: 2022-12-07 21:43:54,166: log_options() 'quotes_text_color = [255, 255, 255]'
INFO: 2022-12-07 21:43:54,166: log_options() 'quotes_text_shadow = False'
INFO: 2022-12-07 21:43:54,166: log_options() 'quotes_vpos = 40'
INFO: 2022-12-07 21:43:54,166: log_options() 'quotes_width = 70'
INFO: 2022-12-07 21:43:54,166: log_options() 'safe_mode = False'
INFO: 2022-12-07 21:43:54,166: log_options() 'slideshow_custom_enabled = False'
INFO: 2022-12-07 21:43:54,166: log_options() 'slideshow_custom_folder = /home/abhinavgorantla/Pictures'
INFO: 2022-12-07 21:43:54,166: log_options() 'slideshow_downloads_enabled = False'
INFO: 2022-12-07 21:43:54,166: log_options() 'slideshow_fade = 0.4'
INFO: 2022-12-07 21:43:54,166: log_options() 'slideshow_favorites_enabled = True'
INFO: 2022-12-07 21:43:54,166: log_options() 'slideshow_mode = Fullscreen'
INFO: 2022-12-07 21:43:54,166: log_options() 'slideshow_monitor = All'
INFO: 2022-12-07 21:43:54,166: log_options() 'slideshow_pan = 0.05'
INFO: 2022-12-07 21:43:54,166: log_options() 'slideshow_seconds = 6.0'
INFO: 2022-12-07 21:43:54,166: log_options() 'slideshow_sort_order = Random'
INFO: 2022-12-07 21:43:54,166: log_options() 'slideshow_sources_enabled = True'
INFO: 2022-12-07 21:43:54,166: log_options() 'slideshow_zoom = 0.2'
INFO: 2022-12-07 21:43:54,167: log_options() 'smart_enabled = False'
INFO: 2022-12-07 21:43:54,167: log_options() 'smart_notice_shown = False'
INFO: 2022-12-07 21:43:54,167: log_options() 'smart_register_shown = False'
INFO: 2022-12-07 21:43:54,167: log_options() 'sources = [[True, 'favorites', 'The Favorites folder'], [True, 'fetched', 'The Fetched folder'], [True, 'folder', '/usr/share/backgrounds'], [True, 'flickr', 'user:www.flickr.com/photos/peter-levi/;user_id:93647178@N00;'], [True, 'apod', 'NASA Astro Pic of the Day'], [True, 'bing', 'Bing Photo of the Day'], [True, 'chromeos', 'Chrome OS Wallpapers'], [True, 'desktoppr', 'Random wallpapers from Desktoppr.co'], [True, 'earthview', 'Google Earth View Wallpapers'], [True, 'unsplash', 'High-resolution photos from Unsplash.com']]'
INFO: 2022-12-07 21:43:54,167: log_options() 'stats_enabled = True'
INFO: 2022-12-07 21:43:54,167: log_options() 'stats_notice_shown = False'
INFO: 2022-12-07 21:43:54,167: log_options() 'sync_enabled = True'
INFO: 2022-12-07 21:43:54,167: log_options() 'use_landscape_enabled = True'
INFO: 2022-12-07 21:43:54,167: reload_config() 'No need to clear prepared queue'
INFO: 2022-12-07 21:43:54,167: update_indicator() 'Setting file info to: /home/abhinavgorantla/.config/variety/Downloaded/nasa_apod/antikythera_wikipedia_1036.jpg'
INFO: 2022-12-07 21:43:54,171: load_last_change_time() 'Change interval < 6 hours, ignore persisted last_change_time, wait initially the whole interval: 300'
INFO: 2022-12-07 21:43:54,171: update_indicator() 'Setting file info to: /home/abhinavgorantla/.config/variety/Downloaded/nasa_apod/antikythera_wikipedia_1036.jpg'
INFO: 2022-12-07 21:43:54,173: regular_change_thread() 'regular_change thread running'
INFO: 2022-12-07 21:43:54,173: prepare_thread() 'Prepare thread running'
INFO: 2022-12-07 21:43:54,173: get_throttling() 'Chrome OS Wallpapers: parsing serverside options'
INFO: 2022-12-07 21:43:54,173: prepare_thread() 'Prepared buffer contains 0 images'
INFO: 2022-12-07 21:43:54,174: get_throttling() 'Could not parse Chrome OS Wallpapers serverside options, using defaults None, None'
INFO: 2022-12-07 21:43:54,175: prepare_thread() 'Preparing some images'
INFO: 2022-12-07 21:43:54,175: get_throttling() 'Chrome OS Wallpapers: parsing serverside options'
INFO: 2022-12-07 21:43:54,175: get_throttling() 'Could not parse Chrome OS Wallpapers serverside options, using defaults None, None'
INFO: 2022-12-07 21:43:54,175: download_one() 'Chrome OS Wallpapers: Downloading an image, config: None'
INFO: 2022-12-07 21:43:54,175: download_one() 'Chrome OS Wallpapers: Queue size: 0'
INFO: 2022-12-07 21:43:54,175: get_throttling() 'Chrome OS Wallpapers: parsing serverside options'
INFO: 2022-12-07 21:43:54,176: get_throttling() 'Could not parse Chrome OS Wallpapers serverside options, using defaults None, None'
INFO: 2022-12-07 21:43:54,176: update_indicator_icon() 'Creating indicator'
INFO: 2022-12-07 21:43:54,176: download_one() 'Chrome OS Wallpapers: Filling queue'
WARNING: 2022-12-07 21:43:54,247: create_menu() 'Variety Slideshow is not installed. This is an optional extension adding pan-and-zoom slideshows to Variety: see https://github.com/peterlevi/variety-slideshow for details'
INFO: 2022-12-07 21:43:54,251: create_indicator() 'indicator backend: AppIndicator3'
INFO: 2022-12-07 21:43:54,267: set_from_theme_icon() 'Showing indicator icon variety-indicator from GTK theme'
INFO: 2022-12-07 21:43:54,272: do_set_wp() 'Calling do_set_wp with /home/abhinavgorantla/.config/variety/Downloaded/nasa_apod/antikythera_wikipedia_1036.jpg, time: 1670429634.2720914'
INFO: 2022-12-07 21:43:54,288: update_indicator() 'Setting file info to: /home/abhinavgorantla/.config/variety/Downloaded/nasa_apod/antikythera_wikipedia_1036.jpg'
INFO: 2022-12-07 21:43:54,295: list_files() 'More than 1 files in the folders, stop listing'
INFO: 2022-12-07 21:43:54,328: prepare_thread() 'After search prepared buffer contains 91 images'
ERROR: 2022-12-07 21:43:54,539: request() 'SSL Error for url https://storage.googleapis.com/chromeos-wallpaper-public/manifest_en.json:'
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 665, in urlopen
    httplib_response = self._make_request(
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 376, in _make_request
    self._validate_conn(conn)
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 996, in _validate_conn
    conn.connect()
  File "/usr/lib/python3/dist-packages/urllib3/connection.py", line 366, in connect
    self.sock = ssl_wrap_socket(
  File "/usr/lib/python3/dist-packages/urllib3/util/ssl_.py", line 370, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "/usr/lib/python3.8/ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
  File "/usr/lib/python3.8/ssl.py", line 1040, in _create
    self.do_handshake()
  File "/usr/lib/python3.8/ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: CA signature digest algorithm too weak (_ssl.c:1131)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 719, in urlopen
    retries = retries.increment(
  File "/usr/lib/python3/dist-packages/urllib3/util/retry.py", line 436, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='storage.googleapis.com', port=443): Max retries exceeded with url: /chromeos-wallpaper-public/manifest_en.json (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: CA signature digest algorithm too weak (_ssl.c:1131)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 612, in request
    r = requests.request(
  File "/usr/lib/python3/dist-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/usr/lib/python3/dist-packages/requests/adapters.py", line 514, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='storage.googleapis.com', port=443): Max retries exceeded with url: /chromeos-wallpaper-public/manifest_en.json (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: CA signature digest algorithm too weak (_ssl.c:1131)')))
ERROR: 2022-12-07 21:43:54,544: download_one_from() 'Could not download wallpaper:'
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 665, in urlopen
    httplib_response = self._make_request(
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 376, in _make_request
    self._validate_conn(conn)
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 996, in _validate_conn
    conn.connect()
  File "/usr/lib/python3/dist-packages/urllib3/connection.py", line 366, in connect
    self.sock = ssl_wrap_socket(
  File "/usr/lib/python3/dist-packages/urllib3/util/ssl_.py", line 370, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "/usr/lib/python3.8/ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
  File "/usr/lib/python3.8/ssl.py", line 1040, in _create
    self.do_handshake()
  File "/usr/lib/python3.8/ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: CA signature digest algorithm too weak (_ssl.c:1131)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 719, in urlopen
    retries = retries.increment(
  File "/usr/lib/python3/dist-packages/urllib3/util/retry.py", line 436, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='storage.googleapis.com', port=443): Max retries exceeded with url: /chromeos-wallpaper-public/manifest_en.json (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: CA signature digest algorithm too weak (_ssl.c:1131)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/variety/VarietyWindow.py", line 1156, in download_one_from
    file = downloader.download_one()
  File "/usr/lib/python3/dist-packages/variety/plugins/downloaders/DefaultDownloader.py", line 141, in download_one
    items = self.fill_queue()
  File "/usr/lib/python3/dist-packages/variety/plugins/builtin/downloaders/ChromeOSWallpapersDownloader.py", line 54, in fill_queue
    manifest = Util.fetch_json(MANIFEST_URL)
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 643, in fetch_json
    return Util.request(url, data, **request_kwargs).json()
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 612, in request
    r = requests.request(
  File "/usr/lib/python3/dist-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/usr/lib/python3/dist-packages/requests/adapters.py", line 514, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='storage.googleapis.com', port=443): Max retries exceeded with url: /chromeos-wallpaper-public/manifest_en.json (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: CA signature digest algorithm too weak (_ssl.c:1131)')))
INFO: 2022-12-07 21:43:55,477: reload() 'Reloading preferences dialog'
INFO: 2022-12-07 21:43:55,548: get_throttling() 'Desktoppr.co: parsing serverside options'
INFO: 2022-12-07 21:43:55,548: get_throttling() 'Could not parse Desktoppr.co serverside options, using defaults None, None'
INFO: 2022-12-07 21:43:55,548: get_throttling() 'Desktoppr.co: parsing serverside options'
INFO: 2022-12-07 21:43:55,548: get_throttling() 'Could not parse Desktoppr.co serverside options, using defaults None, None'
INFO: 2022-12-07 21:43:55,548: download_one() 'Desktoppr.co: Downloading an image, config: None'
INFO: 2022-12-07 21:43:55,549: download_one() 'Desktoppr.co: Queue size: 0'
INFO: 2022-12-07 21:43:55,549: get_throttling() 'Desktoppr.co: parsing serverside options'
INFO: 2022-12-07 21:43:55,549: get_throttling() 'Could not parse Desktoppr.co serverside options, using defaults None, None'
INFO: 2022-12-07 21:43:55,549: download_one() 'Desktoppr.co: Filling queue'
INFO: 2022-12-07 21:43:56,329: trigger_download() 'Triggering download thread to check if download needed'
ERROR: 2022-12-07 21:43:57,743: download_one_from() 'Could not download wallpaper:'
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/variety/VarietyWindow.py", line 1156, in download_one_from
    file = downloader.download_one()
  File "/usr/lib/python3/dist-packages/variety/plugins/downloaders/DefaultDownloader.py", line 141, in download_one
    items = self.fill_queue()
  File "/usr/lib/python3/dist-packages/variety/plugins/builtin/downloaders/DesktopprDownloader.py", line 57, in fill_queue
    response = Util.fetch_json("https://api.desktoppr.co/1/wallpapers/random", verify=False)
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 643, in fetch_json
    return Util.request(url, data, **request_kwargs).json()
  File "/usr/lib/python3/dist-packages/requests/models.py", line 897, in json
    return complexjson.loads(self.text, **kwargs)
  File "/usr/lib/python3/dist-packages/simplejson/__init__.py", line 518, in loads
    return _default_decoder.decode(s)
  File "/usr/lib/python3/dist-packages/simplejson/decoder.py", line 370, in decode
    obj, end = self.raw_decode(s)
  File "/usr/lib/python3/dist-packages/simplejson/decoder.py", line 400, in raw_decode
    return self.scan_once(s, idx=_w(s, idx).end())
simplejson.errors.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
INFO: 2022-12-07 21:43:58,749: get_throttling() 'Unsplash.com: parsing serverside options'
INFO: 2022-12-07 21:43:58,750: get_throttling() 'Could not parse Unsplash.com serverside options, using defaults 20, 3'
INFO: 2022-12-07 21:43:58,750: get_throttling() 'Unsplash.com: parsing serverside options'
INFO: 2022-12-07 21:43:58,750: get_throttling() 'Could not parse Unsplash.com serverside options, using defaults 20, 3'
INFO: 2022-12-07 21:43:58,750: download_one() 'Unsplash.com: Downloading an image, config: None'
INFO: 2022-12-07 21:43:58,750: download_one() 'Unsplash.com: Queue size: 0'
INFO: 2022-12-07 21:43:58,750: get_throttling() 'Unsplash.com: parsing serverside options'
INFO: 2022-12-07 21:43:58,751: get_throttling() 'Could not parse Unsplash.com serverside options, using defaults 20, 3'
INFO: 2022-12-07 21:43:58,751: download_one() 'Unsplash.com: Filling queue'
INFO: 2022-12-07 21:43:58,751: fill_queue() 'Filling Unsplash queue from https://api.unsplash.com/photos/random?count=30&client_id=072e5048dfcb73a8d9ad59fcf402471518ff8df725df462b0c4fa665f466515a&orientation=landscape'
ERROR: 2022-12-07 21:44:00,907: request() 'SSL Error for url https://api.unsplash.com/photos/random?count=30&client_id=072e5048dfcb73a8d9ad59fcf402471518ff8df725df462b0c4fa665f466515a&orientation=landscape:'
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 665, in urlopen
    httplib_response = self._make_request(
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 376, in _make_request
    self._validate_conn(conn)
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 996, in _validate_conn
    conn.connect()
  File "/usr/lib/python3/dist-packages/urllib3/connection.py", line 366, in connect
    self.sock = ssl_wrap_socket(
  File "/usr/lib/python3/dist-packages/urllib3/util/ssl_.py", line 370, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "/usr/lib/python3.8/ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
  File "/usr/lib/python3.8/ssl.py", line 1040, in _create
    self.do_handshake()
  File "/usr/lib/python3.8/ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: CA signature digest algorithm too weak (_ssl.c:1131)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 719, in urlopen
    retries = retries.increment(
  File "/usr/lib/python3/dist-packages/urllib3/util/retry.py", line 436, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='api.unsplash.com', port=443): Max retries exceeded with url: /photos/random?count=30&client_id=072e5048dfcb73a8d9ad59fcf402471518ff8df725df462b0c4fa665f466515a&orientation=landscape (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: CA signature digest algorithm too weak (_ssl.c:1131)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 612, in request
    r = requests.request(
  File "/usr/lib/python3/dist-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/usr/lib/python3/dist-packages/requests/adapters.py", line 514, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='api.unsplash.com', port=443): Max retries exceeded with url: /photos/random?count=30&client_id=072e5048dfcb73a8d9ad59fcf402471518ff8df725df462b0c4fa665f466515a&orientation=landscape (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: CA signature digest algorithm too weak (_ssl.c:1131)')))
ERROR: 2022-12-07 21:44:00,908: download_one_from() 'Could not download wallpaper:'
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 665, in urlopen
    httplib_response = self._make_request(
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 376, in _make_request
    self._validate_conn(conn)
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 996, in _validate_conn
    conn.connect()
  File "/usr/lib/python3/dist-packages/urllib3/connection.py", line 366, in connect
    self.sock = ssl_wrap_socket(
  File "/usr/lib/python3/dist-packages/urllib3/util/ssl_.py", line 370, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "/usr/lib/python3.8/ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
  File "/usr/lib/python3.8/ssl.py", line 1040, in _create
    self.do_handshake()
  File "/usr/lib/python3.8/ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: CA signature digest algorithm too weak (_ssl.c:1131)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 719, in urlopen
    retries = retries.increment(
  File "/usr/lib/python3/dist-packages/urllib3/util/retry.py", line 436, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='api.unsplash.com', port=443): Max retries exceeded with url: /photos/random?count=30&client_id=072e5048dfcb73a8d9ad59fcf402471518ff8df725df462b0c4fa665f466515a&orientation=landscape (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: CA signature digest algorithm too weak (_ssl.c:1131)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/variety/VarietyWindow.py", line 1156, in download_one_from
    file = downloader.download_one()
  File "/usr/lib/python3/dist-packages/variety/plugins/downloaders/DefaultDownloader.py", line 141, in download_one
    items = self.fill_queue()
  File "/usr/lib/python3/dist-packages/variety/plugins/builtin/downloaders/UnsplashDownloader.py", line 83, in fill_queue
    r = Util.request(url)
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 612, in request
    r = requests.request(
  File "/usr/lib/python3/dist-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/usr/lib/python3/dist-packages/requests/adapters.py", line 514, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='api.unsplash.com', port=443): Max retries exceeded with url: /photos/random?count=30&client_id=072e5048dfcb73a8d9ad59fcf402471518ff8df725df462b0c4fa665f466515a&orientation=landscape (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: CA signature digest algorithm too weak (_ssl.c:1131)')))
INFO: 2022-12-07 21:44:01,910: get_throttling() 'Bing: parsing serverside options'
INFO: 2022-12-07 21:44:01,911: get_throttling() 'Could not parse Bing serverside options, using defaults None, None'
INFO: 2022-12-07 21:44:01,911: get_throttling() 'Bing: parsing serverside options'
INFO: 2022-12-07 21:44:01,911: get_throttling() 'Could not parse Bing serverside options, using defaults None, None'
INFO: 2022-12-07 21:44:01,911: download_one() 'Bing: Downloading an image, config: None'
INFO: 2022-12-07 21:44:01,912: download_one() 'Bing: Queue size: 0'
INFO: 2022-12-07 21:44:01,912: get_throttling() 'Bing: parsing serverside options'
INFO: 2022-12-07 21:44:01,912: get_throttling() 'Could not parse Bing serverside options, using defaults None, None'
INFO: 2022-12-07 21:44:01,912: download_one() 'Bing: Filling queue'
ERROR: 2022-12-07 21:44:01,958: request() 'SSL Error for url https://www.bing.com/HPImageArchive.aspx?format=js&idx=0&n=100&mkt=en-US:'
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 665, in urlopen
    httplib_response = self._make_request(
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 376, in _make_request
    self._validate_conn(conn)
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 996, in _validate_conn
    conn.connect()
  File "/usr/lib/python3/dist-packages/urllib3/connection.py", line 366, in connect
    self.sock = ssl_wrap_socket(
  File "/usr/lib/python3/dist-packages/urllib3/util/ssl_.py", line 370, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "/usr/lib/python3.8/ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
  File "/usr/lib/python3.8/ssl.py", line 1040, in _create
    self.do_handshake()
  File "/usr/lib/python3.8/ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: CA signature digest algorithm too weak (_ssl.c:1131)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 719, in urlopen
    retries = retries.increment(
  File "/usr/lib/python3/dist-packages/urllib3/util/retry.py", line 436, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.bing.com', port=443): Max retries exceeded with url: /HPImageArchive.aspx?format=js&idx=0&n=100&mkt=en-US (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: CA signature digest algorithm too weak (_ssl.c:1131)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 612, in request
    r = requests.request(
  File "/usr/lib/python3/dist-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/usr/lib/python3/dist-packages/requests/adapters.py", line 514, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='www.bing.com', port=443): Max retries exceeded with url: /HPImageArchive.aspx?format=js&idx=0&n=100&mkt=en-US (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: CA signature digest algorithm too weak (_ssl.c:1131)')))
ERROR: 2022-12-07 21:44:01,959: download_one_from() 'Could not download wallpaper:'
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 665, in urlopen
    httplib_response = self._make_request(
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 376, in _make_request
    self._validate_conn(conn)
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 996, in _validate_conn
    conn.connect()
  File "/usr/lib/python3/dist-packages/urllib3/connection.py", line 366, in connect
    self.sock = ssl_wrap_socket(
  File "/usr/lib/python3/dist-packages/urllib3/util/ssl_.py", line 370, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "/usr/lib/python3.8/ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
  File "/usr/lib/python3.8/ssl.py", line 1040, in _create
    self.do_handshake()
  File "/usr/lib/python3.8/ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: CA signature digest algorithm too weak (_ssl.c:1131)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 719, in urlopen
    retries = retries.increment(
  File "/usr/lib/python3/dist-packages/urllib3/util/retry.py", line 436, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.bing.com', port=443): Max retries exceeded with url: /HPImageArchive.aspx?format=js&idx=0&n=100&mkt=en-US (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: CA signature digest algorithm too weak (_ssl.c:1131)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/variety/VarietyWindow.py", line 1156, in download_one_from
    file = downloader.download_one()
  File "/usr/lib/python3/dist-packages/variety/plugins/downloaders/DefaultDownloader.py", line 141, in download_one
    items = self.fill_queue()
  File "/usr/lib/python3/dist-packages/variety/plugins/builtin/downloaders/BingDownloader.py", line 61, in fill_queue
    s = Util.fetch_json(BingDownloader.BING_JSON_URL)
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 643, in fetch_json
    return Util.request(url, data, **request_kwargs).json()
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 612, in request
    r = requests.request(
  File "/usr/lib/python3/dist-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/usr/lib/python3/dist-packages/requests/adapters.py", line 514, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='www.bing.com', port=443): Max retries exceeded with url: /HPImageArchive.aspx?format=js&idx=0&n=100&mkt=en-US (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: CA signature digest algorithm too weak (_ssl.c:1131)')))
INFO: 2022-12-07 21:44:02,963: get_throttling() 'NASA Astro Pic of the Day: parsing serverside options'
INFO: 2022-12-07 21:44:02,963: get_throttling() 'Could not parse NASA Astro Pic of the Day serverside options, using defaults None, None'
INFO: 2022-12-07 21:44:02,964: get_throttling() 'NASA Astro Pic of the Day: parsing serverside options'
INFO: 2022-12-07 21:44:02,964: get_throttling() 'Could not parse NASA Astro Pic of the Day serverside options, using defaults None, None'
INFO: 2022-12-07 21:44:02,964: download_one() 'NASA Astro Pic of the Day: Downloading an image, config: None'
INFO: 2022-12-07 21:44:02,964: download_one() 'NASA Astro Pic of the Day: Queue size: 0'
INFO: 2022-12-07 21:44:02,964: get_throttling() 'NASA Astro Pic of the Day: parsing serverside options'
INFO: 2022-12-07 21:44:02,964: get_throttling() 'Could not parse NASA Astro Pic of the Day serverside options, using defaults None, None'
INFO: 2022-12-07 21:44:02,965: download_one() 'NASA Astro Pic of the Day: Filling queue'
INFO: 2022-12-07 21:44:02,965: fill_queue() 'Filling APOD queue from Archive'
INFO: 2022-12-07 21:44:03,037: download_one() 'NASA Astro Pic of the Day: Queue still empty after fill request'
INFO: 2022-12-07 21:44:14,194: server_options_thread() 'Fetching server options from http://tiny.cc/variety-options-063'
ERROR: 2022-12-07 21:44:14,256: server_options_thread() 'Could not fetch Variety serverside options'
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/variety/VarietyWindow.py", line 1087, in server_options_thread
    self.server_options = Util.fetch_json(VarietyWindow.SERVERSIDE_OPTIONS_URL)
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 643, in fetch_json
    return Util.request(url, data, **request_kwargs).json()
  File "/usr/lib/python3/dist-packages/requests/models.py", line 897, in json
    return complexjson.loads(self.text, **kwargs)
  File "/usr/lib/python3/dist-packages/simplejson/__init__.py", line 518, in loads
    return _default_decoder.decode(s)
  File "/usr/lib/python3/dist-packages/simplejson/decoder.py", line 370, in decode
    obj, end = self.raw_decode(s)
  File "/usr/lib/python3/dist-packages/simplejson/decoder.py", line 400, in raw_decode
    return self.scan_once(s, idx=_w(s, idx).end())
simplejson.errors.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
INFO: 2022-12-07 21:44:44,287: server_options_thread() 'Fetching server options from http://tiny.cc/variety-options-063'
ERROR: 2022-12-07 21:44:44,351: server_options_thread() 'Could not fetch Variety serverside options'
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/variety/VarietyWindow.py", line 1087, in server_options_thread
    self.server_options = Util.fetch_json(VarietyWindow.SERVERSIDE_OPTIONS_URL)
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 643, in fetch_json
    return Util.request(url, data, **request_kwargs).json()
  File "/usr/lib/python3/dist-packages/requests/models.py", line 897, in json
    return complexjson.loads(self.text, **kwargs)
  File "/usr/lib/python3/dist-packages/simplejson/__init__.py", line 518, in loads
    return _default_decoder.decode(s)
  File "/usr/lib/python3/dist-packages/simplejson/decoder.py", line 370, in decode
    obj, end = self.raw_decode(s)
  File "/usr/lib/python3/dist-packages/simplejson/decoder.py", line 400, in raw_decode
    return self.scan_once(s, idx=_w(s, idx).end())
simplejson.errors.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
INFO: 2022-12-07 21:45:14,378: server_options_thread() 'Fetching server options from http://tiny.cc/variety-options-063'
ERROR: 2022-12-07 21:45:14,527: server_options_thread() 'Could not fetch Variety serverside options'
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/variety/VarietyWindow.py", line 1087, in server_options_thread
    self.server_options = Util.fetch_json(VarietyWindow.SERVERSIDE_OPTIONS_URL)
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 643, in fetch_json
    return Util.request(url, data, **request_kwargs).json()
  File "/usr/lib/python3/dist-packages/requests/models.py", line 897, in json
    return complexjson.loads(self.text, **kwargs)
  File "/usr/lib/python3/dist-packages/simplejson/__init__.py", line 518, in loads
    return _default_decoder.decode(s)
  File "/usr/lib/python3/dist-packages/simplejson/decoder.py", line 370, in decode
    obj, end = self.raw_decode(s)
  File "/usr/lib/python3/dist-packages/simplejson/decoder.py", line 400, in raw_decode
    return self.scan_once(s, idx=_w(s, idx).end())
simplejson.errors.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
INFO: 2022-12-07 21:45:44,533: server_options_thread() 'Fetching server options from http://tiny.cc/variety-options-063'
INFO: 2022-12-07 21:45:51,294: server_options_thread() 'Fetched server options: {'flickr': {'min_fill_queue_interval': 1200, 'min_download_interval': 1200}, 'wallbase': {'min_fill_queue_interval': 1800, 'min_download_interval': 1800}, 'wallhaven': {'min_fill_queue_interval': 1800, 'min_download_interval': 1800}, 'wallpapers.net': {'min_fill_queue_interval': 601, 'min_download_interval': 0}, 'unsplash': {'min_fill_queue_interval': 20000000000, 'min_download_interval': 20000000000}, 'unsplash_v2': {'min_fill_queue_interval': 3600, 'min_download_interval': 1800}, 'status_message': {'0.0.1': '', '*': ''}}'
INFO: 2022-12-07 21:47:04,040: get_throttling() 'Chrome OS Wallpapers: parsing serverside options'
INFO: 2022-12-07 21:47:04,040: get_throttling() 'Could not parse Chrome OS Wallpapers serverside options, using defaults None, None'
INFO: 2022-12-07 21:47:04,040: get_throttling() 'Chrome OS Wallpapers: parsing serverside options'
INFO: 2022-12-07 21:47:04,040: get_throttling() 'Could not parse Chrome OS Wallpapers serverside options, using defaults None, None'
INFO: 2022-12-07 21:47:04,040: download_one() 'Chrome OS Wallpapers: Downloading an image, config: None'
INFO: 2022-12-07 21:47:04,040: download_one() 'Chrome OS Wallpapers: Queue size: 0'
INFO: 2022-12-07 21:47:04,040: get_throttling() 'Chrome OS Wallpapers: parsing serverside options'
INFO: 2022-12-07 21:47:04,040: get_throttling() 'Could not parse Chrome OS Wallpapers serverside options, using defaults None, None'
INFO: 2022-12-07 21:47:04,041: download_one() 'Chrome OS Wallpapers: Filling queue'
ERROR: 2022-12-07 21:47:05,547: download_one_from() 'Could not download wallpaper:'
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/variety/VarietyWindow.py", line 1156, in download_one_from
    file = downloader.download_one()
  File "/usr/lib/python3/dist-packages/variety/plugins/downloaders/DefaultDownloader.py", line 141, in download_one
    items = self.fill_queue()
  File "/usr/lib/python3/dist-packages/variety/plugins/builtin/downloaders/ChromeOSWallpapersDownloader.py", line 54, in fill_queue
    manifest = Util.fetch_json(MANIFEST_URL)
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 643, in fetch_json
    return Util.request(url, data, **request_kwargs).json()
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 622, in request
    r.raise_for_status()
  File "/usr/lib/python3/dist-packages/requests/models.py", line 940, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://storage.googleapis.com/chromeos-wallpaper-public/manifest_en.json
INFO: 2022-12-07 21:47:06,550: get_throttling() 'Desktoppr.co: parsing serverside options'
INFO: 2022-12-07 21:47:06,550: get_throttling() 'Could not parse Desktoppr.co serverside options, using defaults None, None'
INFO: 2022-12-07 21:47:06,550: get_throttling() 'Desktoppr.co: parsing serverside options'
INFO: 2022-12-07 21:47:06,550: get_throttling() 'Could not parse Desktoppr.co serverside options, using defaults None, None'
INFO: 2022-12-07 21:47:06,550: download_one() 'Desktoppr.co: Downloading an image, config: None'
INFO: 2022-12-07 21:47:06,550: download_one() 'Desktoppr.co: Queue size: 0'
INFO: 2022-12-07 21:47:06,550: get_throttling() 'Desktoppr.co: parsing serverside options'
INFO: 2022-12-07 21:47:06,550: get_throttling() 'Could not parse Desktoppr.co serverside options, using defaults None, None'
INFO: 2022-12-07 21:47:06,550: download_one() 'Desktoppr.co: Filling queue'
ERROR: 2022-12-07 21:47:08,993: download_one_from() 'Could not download wallpaper:'
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/urllib3/connection.py", line 159, in _new_conn
    conn = connection.create_connection(
  File "/usr/lib/python3/dist-packages/urllib3/util/connection.py", line 84, in create_connection
    raise err
  File "/usr/lib/python3/dist-packages/urllib3/util/connection.py", line 74, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 665, in urlopen
    httplib_response = self._make_request(
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 376, in _make_request
    self._validate_conn(conn)
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 996, in _validate_conn
    conn.connect()
  File "/usr/lib/python3/dist-packages/urllib3/connection.py", line 314, in connect
    conn = self._new_conn()
  File "/usr/lib/python3/dist-packages/urllib3/connection.py", line 171, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.VerifiedHTTPSConnection object at 0x7f20142b0c40>: Failed to establish a new connection: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 719, in urlopen
    retries = retries.increment(
  File "/usr/lib/python3/dist-packages/urllib3/util/retry.py", line 436, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='api.desktoppr.co', port=443): Max retries exceeded with url: /1/wallpapers/random (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f20142b0c40>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/variety/VarietyWindow.py", line 1156, in download_one_from
    file = downloader.download_one()
  File "/usr/lib/python3/dist-packages/variety/plugins/downloaders/DefaultDownloader.py", line 141, in download_one
    items = self.fill_queue()
  File "/usr/lib/python3/dist-packages/variety/plugins/builtin/downloaders/DesktopprDownloader.py", line 57, in fill_queue
    response = Util.fetch_json("https://api.desktoppr.co/1/wallpapers/random", verify=False)
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 643, in fetch_json
    return Util.request(url, data, **request_kwargs).json()
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 612, in request
    r = requests.request(
  File "/usr/lib/python3/dist-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/usr/lib/python3/dist-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='api.desktoppr.co', port=443): Max retries exceeded with url: /1/wallpapers/random (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f20142b0c40>: Failed to establish a new connection: [Errno 111] Connection refused'))
INFO: 2022-12-07 21:47:09,995: get_throttling() 'Unsplash.com: parsing serverside options'
INFO: 2022-12-07 21:47:09,996: get_throttling() 'Unsplash.com serverside options: {'min_fill_queue_interval': 3600, 'min_download_interval': 1800}'
INFO: 2022-12-07 21:47:09,996: get_throttling() 'Unsplash.com: parsing serverside options'
INFO: 2022-12-07 21:47:09,996: get_throttling() 'Unsplash.com serverside options: {'min_fill_queue_interval': 3600, 'min_download_interval': 1800}'
INFO: 2022-12-07 21:47:09,996: download_one() 'Unsplash.com: Downloading an image, config: None'
INFO: 2022-12-07 21:47:09,996: download_one() 'Unsplash.com: Queue size: 0'
INFO: 2022-12-07 21:47:09,996: get_throttling() 'Unsplash.com: parsing serverside options'
INFO: 2022-12-07 21:47:09,996: get_throttling() 'Unsplash.com serverside options: {'min_fill_queue_interval': 3600, 'min_download_interval': 1800}'
INFO: 2022-12-07 21:47:09,996: download_one() 'Unsplash.com: Filling queue'
INFO: 2022-12-07 21:47:09,996: fill_queue() 'Filling Unsplash queue from https://api.unsplash.com/photos/random?count=30&client_id=072e5048dfcb73a8d9ad59fcf402471518ff8df725df462b0c4fa665f466515a&orientation=landscape'
ERROR: 2022-12-07 21:47:10,563: fill_queue() 'Could not process an item from Unsplash'
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/variety/plugins/builtin/downloaders/UnsplashDownloader.py", line 105, in fill_queue
    "keywords": [cat["title"].lower().strip() for cat in item["categories"]],
KeyError: 'categories'
ERROR: 2022-12-07 21:47:10,563: download_one_from() 'Could not download wallpaper:'
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/variety/VarietyWindow.py", line 1156, in download_one_from
    file = downloader.download_one()
  File "/usr/lib/python3/dist-packages/variety/plugins/downloaders/DefaultDownloader.py", line 141, in download_one
    items = self.fill_queue()
  File "/usr/lib/python3/dist-packages/variety/plugins/builtin/downloaders/UnsplashDownloader.py", line 105, in fill_queue
    "keywords": [cat["title"].lower().strip() for cat in item["categories"]],
KeyError: 'categories'
INFO: 2022-12-07 21:47:11,565: get_throttling() 'Bing: parsing serverside options'
INFO: 2022-12-07 21:47:11,565: get_throttling() 'Could not parse Bing serverside options, using defaults None, None'
INFO: 2022-12-07 21:47:11,565: get_throttling() 'Bing: parsing serverside options'
INFO: 2022-12-07 21:47:11,566: get_throttling() 'Could not parse Bing serverside options, using defaults None, None'
INFO: 2022-12-07 21:47:11,566: download_one() 'Bing: Downloading an image, config: None'
INFO: 2022-12-07 21:47:11,566: download_one() 'Bing: Queue size: 0'
INFO: 2022-12-07 21:47:11,566: get_throttling() 'Bing: parsing serverside options'
INFO: 2022-12-07 21:47:11,566: get_throttling() 'Could not parse Bing serverside options, using defaults None, None'
INFO: 2022-12-07 21:47:11,566: download_one() 'Bing: Filling queue'
INFO: 2022-12-07 21:47:13,884: download_one() 'Bing: Queue populated with 7 URLs'
INFO: 2022-12-07 21:47:13,885: save_locally() 'Origin URL: https://www.bing.com/search?q=great+egret&form=hpcapt&filters=HpDate%3a%2220221206_0800%22'
INFO: 2022-12-07 21:47:13,885: save_locally() 'Image URL: https://www.bing.com/th?id=OHR.GreatEgret_EN-US1489292796_1920x1080.jpg&rf=LaDigue_1920x1080.jpg&pid=hp'
INFO: 2022-12-07 21:47:13,885: save_locally() 'Local path: /home/abhinavgorantla/.config/variety/Downloaded/Bing/OHR.GreatEgret_EN-US1489292796_1920x1080.jpg'
INFO: 2022-12-07 21:47:13,885: save_locally() 'File already exists, skip downloading'
INFO: 2022-12-07 21:47:14,887: get_throttling() 'NASA Astro Pic of the Day: parsing serverside options'
INFO: 2022-12-07 21:47:14,887: get_throttling() 'Could not parse NASA Astro Pic of the Day serverside options, using defaults None, None'
INFO: 2022-12-07 21:47:14,887: get_throttling() 'NASA Astro Pic of the Day: parsing serverside options'
INFO: 2022-12-07 21:47:14,887: get_throttling() 'Could not parse NASA Astro Pic of the Day serverside options, using defaults None, None'
INFO: 2022-12-07 21:47:14,887: download_one() 'NASA Astro Pic of the Day: Downloading an image, config: None'
INFO: 2022-12-07 21:47:14,887: download_one() 'NASA Astro Pic of the Day: Queue size: 0'
INFO: 2022-12-07 21:47:14,887: get_throttling() 'NASA Astro Pic of the Day: parsing serverside options'
INFO: 2022-12-07 21:47:14,887: get_throttling() 'Could not parse NASA Astro Pic of the Day serverside options, using defaults None, None'
INFO: 2022-12-07 21:47:14,887: download_one() 'NASA Astro Pic of the Day: Filling queue'
INFO: 2022-12-07 21:47:14,888: fill_queue() 'Filling APOD queue from Archive'
ERROR: 2022-12-07 21:47:49,543: download_one_from() 'Could not download wallpaper:'
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/urllib3/response.py", line 425, in _error_catcher
    yield
  File "/usr/lib/python3/dist-packages/urllib3/response.py", line 755, in read_chunked
    chunk = self._handle_chunk(amt)
  File "/usr/lib/python3/dist-packages/urllib3/response.py", line 699, in _handle_chunk
    value = self._fp._safe_read(amt)
  File "/usr/lib/python3.8/http/client.py", line 613, in _safe_read
    data = self.fp.read(amt)
  File "/usr/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/usr/lib/python3.8/ssl.py", line 1241, in recv_into
    return self.read(nbytes, buffer)
  File "/usr/lib/python3.8/ssl.py", line 1099, in read
    return self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/requests/models.py", line 750, in generate
    for chunk in self.raw.stream(chunk_size, decode_content=True):
  File "/usr/lib/python3/dist-packages/urllib3/response.py", line 560, in stream
    for line in self.read_chunked(amt, decode_content=decode_content):
  File "/usr/lib/python3/dist-packages/urllib3/response.py", line 781, in read_chunked
    self._original_response.close()
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/lib/python3/dist-packages/urllib3/response.py", line 430, in _error_catcher
    raise ReadTimeoutError(self._pool, None, "Read timed out.")
urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='apod.nasa.gov', port=443): Read timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/variety/VarietyWindow.py", line 1156, in download_one_from
    file = downloader.download_one()
  File "/usr/lib/python3/dist-packages/variety/plugins/downloaders/DefaultDownloader.py", line 141, in download_one
    items = self.fill_queue()
  File "/usr/lib/python3/dist-packages/variety/plugins/builtin/downloaders/APODDownloader.py", line 59, in fill_queue
    s = Util.html_soup(self.ROOT_URL + "archivepix.html")
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 647, in html_soup
    return bs4.BeautifulSoup(Util.fetch(url, data, **request_kwargs), "lxml")
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 635, in fetch
    return Util.request(url, data, **request_kwargs).text
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 612, in request
    r = requests.request(
  File "/usr/lib/python3/dist-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 668, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 668, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 239, in resolve_redirects
    resp = self.send(
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 686, in send
    r.content
  File "/usr/lib/python3/dist-packages/requests/models.py", line 828, in content
    self._content = b''.join(self.iter_content(CONTENT_CHUNK_SIZE)) or b''
  File "/usr/lib/python3/dist-packages/requests/models.py", line 757, in generate
    raise ConnectionError(e)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='apod.nasa.gov', port=443): Read timed out.
INFO: 2022-12-07 21:48:54,171: regular_change_thread() 'regular_change changes wallpaper'
INFO: 2022-12-07 21:48:54,172: set_wallpaper() 'Calling set_wallpaper with /home/abhinavgorantla/.config/variety/Downloaded/flickr_user_www_flickr_com_photos_peter_levi__user_id_93647178_N00_/7527796276_acde3a08ed_o.jpg'
INFO: 2022-12-07 21:48:54,172: prepare_thread() 'Prepared buffer contains 91 images'
INFO: 2022-12-07 21:48:54,173: do_set_wp() 'Calling do_set_wp with /home/abhinavgorantla/.config/variety/Downloaded/flickr_user_www_flickr_com_photos_peter_levi__user_id_93647178_N00_/7527796276_acde3a08ed_o.jpg, time: 1670429934.1733048'
INFO: 2022-12-07 21:48:54,187: update_indicator() 'Setting file info to: /home/abhinavgorantla/.config/variety/Downloaded/flickr_user_www_flickr_com_photos_peter_levi__user_id_93647178_N00_/7527796276_acde3a08ed_o.jpg'
INFO: 2022-12-07 21:48:54,192: list_files() 'More than 1 files in the folders, stop listing'
INFO: 2022-12-07 21:48:56,172: trigger_download() 'Triggering download thread to check if download needed'
INFO: 2022-12-07 21:48:56,173: trigger_download() 'Triggering download thread to check if download needed'
INFO: 2022-12-07 21:48:56,173: get_throttling() 'Chrome OS Wallpapers: parsing serverside options'
INFO: 2022-12-07 21:48:56,174: get_throttling() 'Could not parse Chrome OS Wallpapers serverside options, using defaults None, None'
INFO: 2022-12-07 21:48:56,174: get_throttling() 'Chrome OS Wallpapers: parsing serverside options'
INFO: 2022-12-07 21:48:56,174: get_throttling() 'Could not parse Chrome OS Wallpapers serverside options, using defaults None, None'
INFO: 2022-12-07 21:48:56,174: download_one() 'Chrome OS Wallpapers: Downloading an image, config: None'
INFO: 2022-12-07 21:48:56,174: download_one() 'Chrome OS Wallpapers: Queue size: 0'
INFO: 2022-12-07 21:48:56,174: get_throttling() 'Chrome OS Wallpapers: parsing serverside options'
INFO: 2022-12-07 21:48:56,174: get_throttling() 'Could not parse Chrome OS Wallpapers serverside options, using defaults None, None'
INFO: 2022-12-07 21:48:56,174: download_one() 'Chrome OS Wallpapers: Filling queue'
ERROR: 2022-12-07 21:48:57,953: download_one_from() 'Could not download wallpaper:'
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/variety/VarietyWindow.py", line 1156, in download_one_from
  File "/usr/lib/python3/dist-packages/variety/plugins/downloaders/DefaultDownloader.py", line 141, in download_one
  File "/usr/lib/python3/dist-packages/variety/plugins/builtin/downloaders/ChromeOSWallpapersDownloader.py", line 54, in fill_queue
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 643, in fetch_json
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 622, in request
  File "/usr/lib/python3/dist-packages/requests/models.py", line 940, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://storage.googleapis.com/chromeos-wallpaper-public/manifest_en.json
INFO: 2022-12-07 21:48:58,956: get_throttling() 'Desktoppr.co: parsing serverside options'
INFO: 2022-12-07 21:48:58,956: get_throttling() 'Could not parse Desktoppr.co serverside options, using defaults None, None'
INFO: 2022-12-07 21:48:58,956: get_throttling() 'Desktoppr.co: parsing serverside options'
INFO: 2022-12-07 21:48:58,956: get_throttling() 'Could not parse Desktoppr.co serverside options, using defaults None, None'
INFO: 2022-12-07 21:48:58,956: download_one() 'Desktoppr.co: Downloading an image, config: None'
INFO: 2022-12-07 21:48:58,957: download_one() 'Desktoppr.co: Queue size: 0'
INFO: 2022-12-07 21:48:58,957: get_throttling() 'Desktoppr.co: parsing serverside options'
INFO: 2022-12-07 21:48:58,957: get_throttling() 'Could not parse Desktoppr.co serverside options, using defaults None, None'
INFO: 2022-12-07 21:48:58,957: download_one() 'Desktoppr.co: Filling queue'
ERROR: 2022-12-07 21:48:59,796: download_one_from() 'Could not download wallpaper:'
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/urllib3/connection.py", line 159, in _new_conn
    conn = connection.create_connection(
  File "/usr/lib/python3/dist-packages/urllib3/util/connection.py", line 84, in create_connection
    raise err
  File "/usr/lib/python3/dist-packages/urllib3/util/connection.py", line 74, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 665, in urlopen
    httplib_response = self._make_request(
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 376, in _make_request
    self._validate_conn(conn)
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 996, in _validate_conn
    conn.connect()
  File "/usr/lib/python3/dist-packages/urllib3/connection.py", line 314, in connect
    conn = self._new_conn()
  File "/usr/lib/python3/dist-packages/urllib3/connection.py", line 171, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.VerifiedHTTPSConnection object at 0x7f201441ed90>: Failed to establish a new connection: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 719, in urlopen
    retries = retries.increment(
  File "/usr/lib/python3/dist-packages/urllib3/util/retry.py", line 436, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='api.desktoppr.co', port=443): Max retries exceeded with url: /1/wallpapers/random (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f201441ed90>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/variety/VarietyWindow.py", line 1156, in download_one_from
  File "/usr/lib/python3/dist-packages/variety/plugins/downloaders/DefaultDownloader.py", line 141, in download_one
  File "/usr/lib/python3/dist-packages/variety/plugins/builtin/downloaders/DesktopprDownloader.py", line 57, in fill_queue
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 643, in fetch_json
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 612, in request
  File "/usr/lib/python3/dist-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/usr/lib/python3/dist-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='api.desktoppr.co', port=443): Max retries exceeded with url: /1/wallpapers/random (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f201441ed90>: Failed to establish a new connection: [Errno 111] Connection refused'))
INFO: 2022-12-07 21:49:00,800: get_throttling() 'Unsplash.com: parsing serverside options'
INFO: 2022-12-07 21:49:00,800: get_throttling() 'Unsplash.com serverside options: {'min_fill_queue_interval': 3600, 'min_download_interval': 1800}'
INFO: 2022-12-07 21:49:00,800: get_throttling() 'Unsplash.com: parsing serverside options'
INFO: 2022-12-07 21:49:00,800: get_throttling() 'Unsplash.com serverside options: {'min_fill_queue_interval': 3600, 'min_download_interval': 1800}'
INFO: 2022-12-07 21:49:00,800: download_one() 'Unsplash.com: Downloading an image, config: None'
INFO: 2022-12-07 21:49:00,800: download_one() 'Unsplash.com: Queue size: 0'
INFO: 2022-12-07 21:49:00,800: get_throttling() 'Unsplash.com: parsing serverside options'
INFO: 2022-12-07 21:49:00,800: get_throttling() 'Unsplash.com serverside options: {'min_fill_queue_interval': 3600, 'min_download_interval': 1800}'
INFO: 2022-12-07 21:49:00,800: download_one() 'Unsplash.com: Filling queue'
INFO: 2022-12-07 21:49:00,800: fill_queue() 'Filling Unsplash queue from https://api.unsplash.com/photos/random?count=30&client_id=072e5048dfcb73a8d9ad59fcf402471518ff8df725df462b0c4fa665f466515a&orientation=landscape'
ERROR: 2022-12-07 21:49:05,976: download_one_from() 'Could not download wallpaper:'
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 421, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 416, in _make_request
    httplib_response = conn.getresponse()
  File "/usr/lib/python3.8/http/client.py", line 1348, in getresponse
    response.begin()
  File "/usr/lib/python3.8/http/client.py", line 316, in begin
    version, status, reason = self._read_status()
  File "/usr/lib/python3.8/http/client.py", line 277, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "/usr/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/usr/lib/python3.8/ssl.py", line 1241, in recv_into
    return self.read(nbytes, buffer)
  File "/usr/lib/python3.8/ssl.py", line 1099, in read
    return self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 719, in urlopen
    retries = retries.increment(
  File "/usr/lib/python3/dist-packages/urllib3/util/retry.py", line 400, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/usr/lib/python3/dist-packages/six.py", line 703, in reraise
    raise value
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 665, in urlopen
    httplib_response = self._make_request(
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 423, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 330, in _raise_timeout
    raise ReadTimeoutError(
urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='api.unsplash.com', port=443): Read timed out. (read timeout=5)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/variety/VarietyWindow.py", line 1156, in download_one_from
  File "/usr/lib/python3/dist-packages/variety/plugins/downloaders/DefaultDownloader.py", line 141, in download_one
  File "/usr/lib/python3/dist-packages/variety/plugins/builtin/downloaders/UnsplashDownloader.py", line 83, in fill_queue
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 612, in request
  File "/usr/lib/python3/dist-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/usr/lib/python3/dist-packages/requests/adapters.py", line 529, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='api.unsplash.com', port=443): Read timed out. (read timeout=5)
INFO: 2022-12-07 21:49:06,978: get_throttling() 'Bing: parsing serverside options'
INFO: 2022-12-07 21:49:06,979: get_throttling() 'Could not parse Bing serverside options, using defaults None, None'
INFO: 2022-12-07 21:49:06,979: get_throttling() 'Bing: parsing serverside options'
INFO: 2022-12-07 21:49:06,979: get_throttling() 'Could not parse Bing serverside options, using defaults None, None'
INFO: 2022-12-07 21:49:06,979: download_one() 'Bing: Downloading an image, config: None'
INFO: 2022-12-07 21:49:06,979: download_one() 'Bing: Queue size: 6'
INFO: 2022-12-07 21:49:06,979: download_one() 'Bing: Queue populated with 6 URLs'
INFO: 2022-12-07 21:49:06,980: save_locally() 'Origin URL: https://www.bing.com/search?q=Tlikakila+River&form=hpcapt&filters=HpDate%3a%2220221202_0800%22'
INFO: 2022-12-07 21:49:06,980: save_locally() 'Image URL: https://www.bing.com/th?id=OHR.BraidedRiverDelta_EN-US0693594934_1920x1080.jpg&rf=LaDigue_1920x1080.jpg&pid=hp'
INFO: 2022-12-07 21:49:06,980: save_locally() 'Local path: /home/abhinavgorantla/.config/variety/Downloaded/Bing/OHR.BraidedRiverDelta_EN-US0693594934_1920x1080.jpg'
INFO: 2022-12-07 21:49:06,980: save_locally() 'File already exists, skip downloading'
INFO: 2022-12-07 21:49:07,982: get_throttling() 'Flickr: parsing serverside options'
INFO: 2022-12-07 21:49:07,982: get_throttling() 'Flickr serverside options: {'min_fill_queue_interval': 1200, 'min_download_interval': 1200}'
INFO: 2022-12-07 21:49:07,982: get_throttling() 'Flickr: parsing serverside options'
INFO: 2022-12-07 21:49:07,983: get_throttling() 'Flickr serverside options: {'min_fill_queue_interval': 1200, 'min_download_interval': 1200}'
INFO: 2022-12-07 21:49:07,983: download_one() 'Flickr: Downloading an image, config: user:www.flickr.com/photos/peter-levi/;user_id:93647178@N00;'
INFO: 2022-12-07 21:49:07,983: download_one() 'Flickr: Queue size: 0'
INFO: 2022-12-07 21:49:07,983: get_throttling() 'Flickr: parsing serverside options'
INFO: 2022-12-07 21:49:07,983: get_throttling() 'Flickr serverside options: {'min_fill_queue_interval': 1200, 'min_download_interval': 1200}'
INFO: 2022-12-07 21:49:07,983: download_one() 'Flickr: Filling queue'
INFO: 2022-12-07 21:49:07,984: fetch() 'Making flickr API call: https://api.flickr.com/services/rest/?method=flickr.photos.search&api_key=0553a848c09bcfd21d3a984d9408c04e&per_page=500&tag_mode=all&format=json&nojsoncallback=1&user_id=93647178@N00'
INFO: 2022-12-07 21:49:09,838: fill_queue() '1 pages in the search results, using page 1'
INFO: 2022-12-07 21:49:09,838: fetch() 'Making flickr API call: https://api.flickr.com/services/rest/?method=flickr.photos.search&api_key=0553a848c09bcfd21d3a984d9408c04e&per_page=500&tag_mode=all&format=json&nojsoncallback=1&user_id=93647178@N00&extras=owner_name,description,tags,o_dims,url_o,url_k,url_h,url_l&page=1'
INFO: 2022-12-07 21:49:10,739: process_photos_in_response() 'Queue size is 0, populating with images for size suffix o'
INFO: 2022-12-07 21:49:10,760: download_one() 'Flickr: Queue populated with 73 URLs'
INFO: 2022-12-07 21:49:10,760: save_locally() 'Origin URL: https://www.flickr.com/photos/93647178@N00/7527938790'
INFO: 2022-12-07 21:49:10,761: save_locally() 'Image URL: https://live.staticflickr.com/7132/7527938790_ab2f5671e2_o.jpg'
INFO: 2022-12-07 21:49:10,761: save_locally() 'Local path: /home/abhinavgorantla/.config/variety/Downloaded/flickr_user_www_flickr_com_photos_peter_levi__user_id_93647178_N00_/7527938790_ab2f5671e2_o.jpg'
INFO: 2022-12-07 21:49:12,576: save_locally() 'Download complete'
INFO: 2022-12-07 21:49:12,577: update_indicator() 'Setting file info to: /home/abhinavgorantla/.config/variety/Downloaded/flickr_user_www_flickr_com_photos_peter_levi__user_id_93647178_N00_/7527796276_acde3a08ed_o.jpg'
INFO: 2022-12-07 21:49:12,582: list_files() 'More than 1 files in the folders, stop listing'
INFO: 2022-12-07 21:49:12,584: download_one_from() 'Adding downloaded file /home/abhinavgorantla/.config/variety/Downloaded/flickr_user_www_flickr_com_photos_peter_levi__user_id_93647178_N00_/7527938790_ab2f5671e2_o.jpg to unseen_downloads'
INFO: 2022-12-07 21:49:13,587: get_throttling() 'NASA Astro Pic of the Day: parsing serverside options'
INFO: 2022-12-07 21:49:13,587: get_throttling() 'Could not parse NASA Astro Pic of the Day serverside options, using defaults None, None'
INFO: 2022-12-07 21:49:13,587: get_throttling() 'NASA Astro Pic of the Day: parsing serverside options'
INFO: 2022-12-07 21:49:13,587: get_throttling() 'Could not parse NASA Astro Pic of the Day serverside options, using defaults None, None'
INFO: 2022-12-07 21:49:13,588: download_one() 'NASA Astro Pic of the Day: Downloading an image, config: None'
INFO: 2022-12-07 21:49:13,588: download_one() 'NASA Astro Pic of the Day: Queue size: 0'
INFO: 2022-12-07 21:49:13,588: get_throttling() 'NASA Astro Pic of the Day: parsing serverside options'
INFO: 2022-12-07 21:49:13,588: get_throttling() 'Could not parse NASA Astro Pic of the Day serverside options, using defaults None, None'
INFO: 2022-12-07 21:49:13,588: download_one() 'NASA Astro Pic of the Day: Filling queue'
INFO: 2022-12-07 21:49:13,588: fill_queue() 'Filling APOD queue from Archive'
ERROR: 2022-12-07 21:49:25,908: download_one_from() 'Could not download wallpaper:'
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/urllib3/response.py", line 425, in _error_catcher
    yield
  File "/usr/lib/python3/dist-packages/urllib3/response.py", line 755, in read_chunked
    chunk = self._handle_chunk(amt)
  File "/usr/lib/python3/dist-packages/urllib3/response.py", line 699, in _handle_chunk
    value = self._fp._safe_read(amt)
  File "/usr/lib/python3.8/http/client.py", line 613, in _safe_read
    data = self.fp.read(amt)
  File "/usr/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/usr/lib/python3.8/ssl.py", line 1241, in recv_into
    return self.read(nbytes, buffer)
  File "/usr/lib/python3.8/ssl.py", line 1099, in read
    return self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/requests/models.py", line 750, in generate
    for chunk in self.raw.stream(chunk_size, decode_content=True):
  File "/usr/lib/python3/dist-packages/urllib3/response.py", line 560, in stream
    for line in self.read_chunked(amt, decode_content=decode_content):
  File "/usr/lib/python3/dist-packages/urllib3/response.py", line 781, in read_chunked
    self._original_response.close()
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/lib/python3/dist-packages/urllib3/response.py", line 430, in _error_catcher
    raise ReadTimeoutError(self._pool, None, "Read timed out.")
urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='apod.nasa.gov', port=443): Read timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/variety/VarietyWindow.py", line 1156, in download_one_from
  File "/usr/lib/python3/dist-packages/variety/plugins/downloaders/DefaultDownloader.py", line 141, in download_one
  File "/usr/lib/python3/dist-packages/variety/plugins/builtin/downloaders/APODDownloader.py", line 59, in fill_queue
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 647, in html_soup
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 635, in fetch
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 612, in request
  File "/usr/lib/python3/dist-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 668, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 668, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 239, in resolve_redirects
    resp = self.send(
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 686, in send
    r.content
  File "/usr/lib/python3/dist-packages/requests/models.py", line 828, in content
    self._content = b''.join(self.iter_content(CONTENT_CHUNK_SIZE)) or b''
  File "/usr/lib/python3/dist-packages/requests/models.py", line 757, in generate
    raise ConnectionError(e)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='apod.nasa.gov', port=443): Read timed out.
INFO: 2022-12-07 21:52:26,914: get_throttling() 'Chrome OS Wallpapers: parsing serverside options'
INFO: 2022-12-07 21:52:26,915: get_throttling() 'Could not parse Chrome OS Wallpapers serverside options, using defaults None, None'
INFO: 2022-12-07 21:52:26,915: get_throttling() 'Chrome OS Wallpapers: parsing serverside options'
INFO: 2022-12-07 21:52:26,915: get_throttling() 'Could not parse Chrome OS Wallpapers serverside options, using defaults None, None'
INFO: 2022-12-07 21:52:26,916: download_one() 'Chrome OS Wallpapers: Downloading an image, config: None'
INFO: 2022-12-07 21:52:26,916: download_one() 'Chrome OS Wallpapers: Queue size: 0'
INFO: 2022-12-07 21:52:26,917: get_throttling() 'Chrome OS Wallpapers: parsing serverside options'
INFO: 2022-12-07 21:52:26,917: get_throttling() 'Could not parse Chrome OS Wallpapers serverside options, using defaults None, None'
INFO: 2022-12-07 21:52:26,917: download_one() 'Chrome OS Wallpapers: Filling queue'
ERROR: 2022-12-07 21:52:28,571: download_one_from() 'Could not download wallpaper:'
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/variety/VarietyWindow.py", line 1156, in download_one_from
  File "/usr/lib/python3/dist-packages/variety/plugins/downloaders/DefaultDownloader.py", line 141, in download_one
  File "/usr/lib/python3/dist-packages/variety/plugins/builtin/downloaders/ChromeOSWallpapersDownloader.py", line 54, in fill_queue
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 643, in fetch_json
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 622, in request
  File "/usr/lib/python3/dist-packages/requests/models.py", line 940, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://storage.googleapis.com/chromeos-wallpaper-public/manifest_en.json
INFO: 2022-12-07 21:52:29,575: get_throttling() 'Desktoppr.co: parsing serverside options'
INFO: 2022-12-07 21:52:29,575: get_throttling() 'Could not parse Desktoppr.co serverside options, using defaults None, None'
INFO: 2022-12-07 21:52:29,575: get_throttling() 'Desktoppr.co: parsing serverside options'
INFO: 2022-12-07 21:52:29,576: get_throttling() 'Could not parse Desktoppr.co serverside options, using defaults None, None'
INFO: 2022-12-07 21:52:29,576: download_one() 'Desktoppr.co: Downloading an image, config: None'
INFO: 2022-12-07 21:52:29,576: download_one() 'Desktoppr.co: Queue size: 0'
INFO: 2022-12-07 21:52:29,576: get_throttling() 'Desktoppr.co: parsing serverside options'
INFO: 2022-12-07 21:52:29,576: get_throttling() 'Could not parse Desktoppr.co serverside options, using defaults None, None'
INFO: 2022-12-07 21:52:29,577: download_one() 'Desktoppr.co: Filling queue'
ERROR: 2022-12-07 21:52:29,898: download_one_from() 'Could not download wallpaper:'
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/urllib3/connection.py", line 159, in _new_conn
    conn = connection.create_connection(
  File "/usr/lib/python3/dist-packages/urllib3/util/connection.py", line 84, in create_connection
    raise err
  File "/usr/lib/python3/dist-packages/urllib3/util/connection.py", line 74, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 665, in urlopen
    httplib_response = self._make_request(
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 376, in _make_request
    self._validate_conn(conn)
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 996, in _validate_conn
    conn.connect()
  File "/usr/lib/python3/dist-packages/urllib3/connection.py", line 314, in connect
    conn = self._new_conn()
  File "/usr/lib/python3/dist-packages/urllib3/connection.py", line 171, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.VerifiedHTTPSConnection object at 0x7f2014412040>: Failed to establish a new connection: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 719, in urlopen
    retries = retries.increment(
  File "/usr/lib/python3/dist-packages/urllib3/util/retry.py", line 436, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='api.desktoppr.co', port=443): Max retries exceeded with url: /1/wallpapers/random (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f2014412040>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/variety/VarietyWindow.py", line 1156, in download_one_from
  File "/usr/lib/python3/dist-packages/variety/plugins/downloaders/DefaultDownloader.py", line 141, in download_one
  File "/usr/lib/python3/dist-packages/variety/plugins/builtin/downloaders/DesktopprDownloader.py", line 57, in fill_queue
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 643, in fetch_json
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 612, in request
  File "/usr/lib/python3/dist-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/usr/lib/python3/dist-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='api.desktoppr.co', port=443): Max retries exceeded with url: /1/wallpapers/random (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f2014412040>: Failed to establish a new connection: [Errno 111] Connection refused'))
INFO: 2022-12-07 21:52:30,902: get_throttling() 'Unsplash.com: parsing serverside options'
INFO: 2022-12-07 21:52:30,902: get_throttling() 'Unsplash.com serverside options: {'min_fill_queue_interval': 3600, 'min_download_interval': 1800}'
INFO: 2022-12-07 21:52:30,902: get_throttling() 'Unsplash.com: parsing serverside options'
INFO: 2022-12-07 21:52:30,902: get_throttling() 'Unsplash.com serverside options: {'min_fill_queue_interval': 3600, 'min_download_interval': 1800}'
INFO: 2022-12-07 21:52:30,902: download_one() 'Unsplash.com: Downloading an image, config: None'
INFO: 2022-12-07 21:52:30,903: download_one() 'Unsplash.com: Queue size: 0'
INFO: 2022-12-07 21:52:30,903: get_throttling() 'Unsplash.com: parsing serverside options'
INFO: 2022-12-07 21:52:30,903: get_throttling() 'Unsplash.com serverside options: {'min_fill_queue_interval': 3600, 'min_download_interval': 1800}'
INFO: 2022-12-07 21:52:30,903: download_one() 'Unsplash.com: Queue empty, but max_queue_fills_per_hour of 3 reached, will try again later'
INFO: 2022-12-07 21:52:31,905: get_throttling() 'Bing: parsing serverside options'
INFO: 2022-12-07 21:52:31,905: get_throttling() 'Could not parse Bing serverside options, using defaults None, None'
INFO: 2022-12-07 21:52:31,905: get_throttling() 'Bing: parsing serverside options'
INFO: 2022-12-07 21:52:31,906: get_throttling() 'Could not parse Bing serverside options, using defaults None, None'
INFO: 2022-12-07 21:52:31,906: download_one() 'Bing: Downloading an image, config: None'
INFO: 2022-12-07 21:52:31,906: download_one() 'Bing: Queue size: 5'
INFO: 2022-12-07 21:52:31,906: download_one() 'Bing: Queue populated with 5 URLs'
INFO: 2022-12-07 21:52:31,906: save_locally() 'Origin URL: https://www.bing.com/search?q=Art+Basel+Miami+Beach&form=hpcapt&filters=HpDate%3a%2220221203_0800%22'
INFO: 2022-12-07 21:52:31,907: save_locally() 'Image URL: https://www.bing.com/th?id=OHR.MiamiDT_EN-US0878462019_1920x1080.jpg&rf=LaDigue_1920x1080.jpg&pid=hp'
INFO: 2022-12-07 21:52:31,907: save_locally() 'Local path: /home/abhinavgorantla/.config/variety/Downloaded/Bing/OHR.MiamiDT_EN-US0878462019_1920x1080.jpg'
INFO: 2022-12-07 21:52:31,907: save_locally() 'File already exists, skip downloading'
INFO: 2022-12-07 21:52:32,909: get_throttling() 'NASA Astro Pic of the Day: parsing serverside options'
INFO: 2022-12-07 21:52:32,909: get_throttling() 'Could not parse NASA Astro Pic of the Day serverside options, using defaults None, None'
INFO: 2022-12-07 21:52:32,909: get_throttling() 'NASA Astro Pic of the Day: parsing serverside options'
INFO: 2022-12-07 21:52:32,910: get_throttling() 'Could not parse NASA Astro Pic of the Day serverside options, using defaults None, None'
INFO: 2022-12-07 21:52:32,910: download_one() 'NASA Astro Pic of the Day: Downloading an image, config: None'
INFO: 2022-12-07 21:52:32,910: download_one() 'NASA Astro Pic of the Day: Queue size: 0'
INFO: 2022-12-07 21:52:32,910: get_throttling() 'NASA Astro Pic of the Day: parsing serverside options'
INFO: 2022-12-07 21:52:32,910: get_throttling() 'Could not parse NASA Astro Pic of the Day serverside options, using defaults None, None'
INFO: 2022-12-07 21:52:32,910: download_one() 'NASA Astro Pic of the Day: Filling queue'
INFO: 2022-12-07 21:52:32,911: fill_queue() 'Filling APOD queue from Archive'
INFO: 2022-12-07 21:53:07,298: download_one() 'NASA Astro Pic of the Day: Queue populated with 730 URLs'
INFO: 2022-12-07 21:53:07,298: download_queue_item() 'APOD URL: http://apod.nasa.gov/apod/ap220401.html'
INFO: 2022-12-07 21:53:12,740: download_queue_item() 'Image URL: http://apod.nasa.gov/apod/image/2204/sunspotsleaningtowerofpisa.jpg'
INFO: 2022-12-07 21:53:12,740: save_locally() 'Origin URL: http://apod.nasa.gov/apod/ap220401.html'
INFO: 2022-12-07 21:53:12,740: save_locally() 'Image URL: http://apod.nasa.gov/apod/image/2204/sunspotsleaningtowerofpisa.jpg'
INFO: 2022-12-07 21:53:12,741: save_locally() 'Local path: /home/abhinavgorantla/.config/variety/Downloaded/nasa_apod/sunspotsleaningtowerofpisa.jpg'
INFO: 2022-12-07 21:53:24,092: save_locally() 'Download failed from image URL: http://apod.nasa.gov/apod/image/2204/sunspotsleaningtowerofpisa.jpg (source location: http://apod.nasa.gov/apod/) '
ERROR: 2022-12-07 21:53:24,093: download_one_from() 'Could not download wallpaper:'
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/urllib3/response.py", line 425, in _error_catcher
    yield
  File "/usr/lib/python3/dist-packages/urllib3/response.py", line 507, in read
    data = self._fp.read(amt) if not fp_closed else b""
  File "/usr/lib/python3.8/http/client.py", line 459, in read
    n = self.readinto(b)
  File "/usr/lib/python3.8/http/client.py", line 503, in readinto
    n = self.fp.readinto(b)
  File "/usr/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/usr/lib/python3.8/ssl.py", line 1241, in recv_into
    return self.read(nbytes, buffer)
  File "/usr/lib/python3.8/ssl.py", line 1099, in read
    return self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/requests/models.py", line 750, in generate
    for chunk in self.raw.stream(chunk_size, decode_content=True):
  File "/usr/lib/python3/dist-packages/urllib3/response.py", line 564, in stream
    data = self.read(amt=amt, decode_content=decode_content)
  File "/usr/lib/python3/dist-packages/urllib3/response.py", line 529, in read
    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/lib/python3/dist-packages/urllib3/response.py", line 430, in _error_catcher
    raise ReadTimeoutError(self._pool, None, "Read timed out.")
urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='apod.nasa.gov', port=443): Read timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/variety/VarietyWindow.py", line 1156, in download_one_from
  File "/usr/lib/python3/dist-packages/variety/plugins/downloaders/DefaultDownloader.py", line 153, in download_one
  File "/usr/lib/python3/dist-packages/variety/plugins/builtin/downloaders/APODDownloader.py", line 89, in download_queue_item
  File "/usr/lib/python3/dist-packages/variety/plugins/downloaders/DefaultDownloader.py", line 244, in save_locally
  File "/usr/lib/python3/dist-packages/variety/plugins/downloaders/DefaultDownloader.py", line 237, in save_locally
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 630, in request_write_to
  File "/usr/lib/python3/dist-packages/requests/models.py", line 757, in generate
    raise ConnectionError(e)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='apod.nasa.gov', port=443): Read timed out.
INFO: 2022-12-07 21:53:54,298: regular_change_thread() 'regular_change changes wallpaper'
INFO: 2022-12-07 21:53:54,299: set_wallpaper() 'Calling set_wallpaper with /home/abhinavgorantla/.config/variety/Downloaded/nasa_apod/Needle_Galaxy_4-7-22.jpg'
INFO: 2022-12-07 21:53:54,300: prepare_thread() 'Prepared buffer contains 91 images'
INFO: 2022-12-07 21:53:54,302: do_set_wp() 'Calling do_set_wp with /home/abhinavgorantla/.config/variety/Downloaded/nasa_apod/Needle_Galaxy_4-7-22.jpg, time: 1670430234.3021946'
INFO: 2022-12-07 21:53:54,321: update_indicator() 'Setting file info to: /home/abhinavgorantla/.config/variety/Downloaded/nasa_apod/Needle_Galaxy_4-7-22.jpg'
INFO: 2022-12-07 21:53:54,326: list_files() 'More than 1 files in the folders, stop listing'
INFO: 2022-12-07 21:53:56,301: trigger_download() 'Triggering download thread to check if download needed'
INFO: 2022-12-07 21:53:56,301: get_throttling() 'Chrome OS Wallpapers: parsing serverside options'
INFO: 2022-12-07 21:53:56,302: get_throttling() 'Could not parse Chrome OS Wallpapers serverside options, using defaults None, None'
INFO: 2022-12-07 21:53:56,302: get_throttling() 'Chrome OS Wallpapers: parsing serverside options'
INFO: 2022-12-07 21:53:56,302: get_throttling() 'Could not parse Chrome OS Wallpapers serverside options, using defaults None, None'
INFO: 2022-12-07 21:53:56,303: download_one() 'Chrome OS Wallpapers: Downloading an image, config: None'
INFO: 2022-12-07 21:53:56,303: trigger_download() 'Triggering download thread to check if download needed'
INFO: 2022-12-07 21:53:56,303: download_one() 'Chrome OS Wallpapers: Queue size: 0'
INFO: 2022-12-07 21:53:56,303: get_throttling() 'Chrome OS Wallpapers: parsing serverside options'
INFO: 2022-12-07 21:53:56,303: get_throttling() 'Could not parse Chrome OS Wallpapers serverside options, using defaults None, None'
INFO: 2022-12-07 21:53:56,303: download_one() 'Chrome OS Wallpapers: Filling queue'
ERROR: 2022-12-07 21:53:58,459: download_one_from() 'Could not download wallpaper:'
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/variety/VarietyWindow.py", line 1156, in download_one_from
  File "/usr/lib/python3/dist-packages/variety/plugins/downloaders/DefaultDownloader.py", line 141, in download_one
  File "/usr/lib/python3/dist-packages/variety/plugins/builtin/downloaders/ChromeOSWallpapersDownloader.py", line 54, in fill_queue
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 643, in fetch_json
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 622, in request
  File "/usr/lib/python3/dist-packages/requests/models.py", line 940, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://storage.googleapis.com/chromeos-wallpaper-public/manifest_en.json
INFO: 2022-12-07 21:53:59,464: get_throttling() 'Desktoppr.co: parsing serverside options'
INFO: 2022-12-07 21:53:59,464: get_throttling() 'Could not parse Desktoppr.co serverside options, using defaults None, None'
INFO: 2022-12-07 21:53:59,464: get_throttling() 'Desktoppr.co: parsing serverside options'
INFO: 2022-12-07 21:53:59,464: get_throttling() 'Could not parse Desktoppr.co serverside options, using defaults None, None'
INFO: 2022-12-07 21:53:59,465: download_one() 'Desktoppr.co: Downloading an image, config: None'
INFO: 2022-12-07 21:53:59,465: download_one() 'Desktoppr.co: Queue size: 0'
INFO: 2022-12-07 21:53:59,465: get_throttling() 'Desktoppr.co: parsing serverside options'
INFO: 2022-12-07 21:53:59,465: get_throttling() 'Could not parse Desktoppr.co serverside options, using defaults None, None'
INFO: 2022-12-07 21:53:59,465: download_one() 'Desktoppr.co: Filling queue'
ERROR: 2022-12-07 21:53:59,764: download_one_from() 'Could not download wallpaper:'
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/urllib3/connection.py", line 159, in _new_conn
    conn = connection.create_connection(
  File "/usr/lib/python3/dist-packages/urllib3/util/connection.py", line 84, in create_connection
    raise err
  File "/usr/lib/python3/dist-packages/urllib3/util/connection.py", line 74, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 665, in urlopen
    httplib_response = self._make_request(
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 376, in _make_request
    self._validate_conn(conn)
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 996, in _validate_conn
    conn.connect()
  File "/usr/lib/python3/dist-packages/urllib3/connection.py", line 314, in connect
    conn = self._new_conn()
  File "/usr/lib/python3/dist-packages/urllib3/connection.py", line 171, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.VerifiedHTTPSConnection object at 0x7f2014340940>: Failed to establish a new connection: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 719, in urlopen
    retries = retries.increment(
  File "/usr/lib/python3/dist-packages/urllib3/util/retry.py", line 436, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='api.desktoppr.co', port=443): Max retries exceeded with url: /1/wallpapers/random (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f2014340940>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/variety/VarietyWindow.py", line 1156, in download_one_from
  File "/usr/lib/python3/dist-packages/variety/plugins/downloaders/DefaultDownloader.py", line 141, in download_one
  File "/usr/lib/python3/dist-packages/variety/plugins/builtin/downloaders/DesktopprDownloader.py", line 57, in fill_queue
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 643, in fetch_json
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 612, in request
  File "/usr/lib/python3/dist-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/usr/lib/python3/dist-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='api.desktoppr.co', port=443): Max retries exceeded with url: /1/wallpapers/random (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f2014340940>: Failed to establish a new connection: [Errno 111] Connection refused'))
INFO: 2022-12-07 21:54:00,767: get_throttling() 'Unsplash.com: parsing serverside options'
INFO: 2022-12-07 21:54:00,767: get_throttling() 'Unsplash.com serverside options: {'min_fill_queue_interval': 3600, 'min_download_interval': 1800}'
INFO: 2022-12-07 21:54:00,768: get_throttling() 'Unsplash.com: parsing serverside options'
INFO: 2022-12-07 21:54:00,768: get_throttling() 'Unsplash.com serverside options: {'min_fill_queue_interval': 3600, 'min_download_interval': 1800}'
INFO: 2022-12-07 21:54:00,768: download_one() 'Unsplash.com: Downloading an image, config: None'
INFO: 2022-12-07 21:54:00,768: download_one() 'Unsplash.com: Queue size: 0'
INFO: 2022-12-07 21:54:00,768: get_throttling() 'Unsplash.com: parsing serverside options'
INFO: 2022-12-07 21:54:00,769: get_throttling() 'Unsplash.com serverside options: {'min_fill_queue_interval': 3600, 'min_download_interval': 1800}'
INFO: 2022-12-07 21:54:00,769: download_one() 'Unsplash.com: Queue empty, but max_queue_fills_per_hour of 3 reached, will try again later'
INFO: 2022-12-07 21:54:01,772: get_throttling() 'Bing: parsing serverside options'
INFO: 2022-12-07 21:54:01,772: get_throttling() 'Could not parse Bing serverside options, using defaults None, None'
INFO: 2022-12-07 21:54:01,772: get_throttling() 'Bing: parsing serverside options'
INFO: 2022-12-07 21:54:01,772: get_throttling() 'Could not parse Bing serverside options, using defaults None, None'
INFO: 2022-12-07 21:54:01,773: download_one() 'Bing: Downloading an image, config: None'
INFO: 2022-12-07 21:54:01,773: download_one() 'Bing: Queue size: 4'
INFO: 2022-12-07 21:54:01,773: download_one() 'Bing: Queue populated with 4 URLs'
INFO: 2022-12-07 21:54:01,774: save_locally() 'Origin URL: https://www.bing.com/search?q=antarctica&form=hpcapt&filters=HpDate%3a%2220221201_0800%22'
INFO: 2022-12-07 21:54:01,774: save_locally() 'Image URL: https://www.bing.com/th?id=OHR.AntarcticaDay_EN-US9921573438_1920x1080.jpg&rf=LaDigue_1920x1080.jpg&pid=hp'
INFO: 2022-12-07 21:54:01,774: save_locally() 'Local path: /home/abhinavgorantla/.config/variety/Downloaded/Bing/OHR.AntarcticaDay_EN-US9921573438_1920x1080.jpg'
INFO: 2022-12-07 21:54:01,775: save_locally() 'File already exists, skip downloading'
INFO: 2022-12-07 21:57:02,776: get_throttling() 'Chrome OS Wallpapers: parsing serverside options'
INFO: 2022-12-07 21:57:02,776: get_throttling() 'Could not parse Chrome OS Wallpapers serverside options, using defaults None, None'
INFO: 2022-12-07 21:57:02,776: get_throttling() 'Chrome OS Wallpapers: parsing serverside options'
INFO: 2022-12-07 21:57:02,776: get_throttling() 'Could not parse Chrome OS Wallpapers serverside options, using defaults None, None'
INFO: 2022-12-07 21:57:02,777: download_one() 'Chrome OS Wallpapers: Downloading an image, config: None'
INFO: 2022-12-07 21:57:02,777: download_one() 'Chrome OS Wallpapers: Queue size: 0'
INFO: 2022-12-07 21:57:02,777: get_throttling() 'Chrome OS Wallpapers: parsing serverside options'
INFO: 2022-12-07 21:57:02,777: get_throttling() 'Could not parse Chrome OS Wallpapers serverside options, using defaults None, None'
INFO: 2022-12-07 21:57:02,777: download_one() 'Chrome OS Wallpapers: Filling queue'
ERROR: 2022-12-07 21:57:04,600: download_one_from() 'Could not download wallpaper:'
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/variety/VarietyWindow.py", line 1156, in download_one_from
  File "/usr/lib/python3/dist-packages/variety/plugins/downloaders/DefaultDownloader.py", line 141, in download_one
  File "/usr/lib/python3/dist-packages/variety/plugins/builtin/downloaders/ChromeOSWallpapersDownloader.py", line 54, in fill_queue
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 643, in fetch_json
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 622, in request
  File "/usr/lib/python3/dist-packages/requests/models.py", line 940, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://storage.googleapis.com/chromeos-wallpaper-public/manifest_en.json
INFO: 2022-12-07 21:57:05,602: get_throttling() 'Desktoppr.co: parsing serverside options'
INFO: 2022-12-07 21:57:05,602: get_throttling() 'Could not parse Desktoppr.co serverside options, using defaults None, None'
INFO: 2022-12-07 21:57:05,602: get_throttling() 'Desktoppr.co: parsing serverside options'
INFO: 2022-12-07 21:57:05,602: get_throttling() 'Could not parse Desktoppr.co serverside options, using defaults None, None'
INFO: 2022-12-07 21:57:05,602: download_one() 'Desktoppr.co: Downloading an image, config: None'
INFO: 2022-12-07 21:57:05,603: download_one() 'Desktoppr.co: Queue size: 0'
INFO: 2022-12-07 21:57:05,603: get_throttling() 'Desktoppr.co: parsing serverside options'
INFO: 2022-12-07 21:57:05,603: get_throttling() 'Could not parse Desktoppr.co serverside options, using defaults None, None'
INFO: 2022-12-07 21:57:05,603: download_one() 'Desktoppr.co: Filling queue'
ERROR: 2022-12-07 21:57:06,014: download_one_from() 'Could not download wallpaper:'
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/urllib3/connection.py", line 159, in _new_conn
    conn = connection.create_connection(
  File "/usr/lib/python3/dist-packages/urllib3/util/connection.py", line 84, in create_connection
    raise err
  File "/usr/lib/python3/dist-packages/urllib3/util/connection.py", line 74, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 665, in urlopen
    httplib_response = self._make_request(
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 376, in _make_request
    self._validate_conn(conn)
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 996, in _validate_conn
    conn.connect()
  File "/usr/lib/python3/dist-packages/urllib3/connection.py", line 314, in connect
    conn = self._new_conn()
  File "/usr/lib/python3/dist-packages/urllib3/connection.py", line 171, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.VerifiedHTTPSConnection object at 0x7f200577d340>: Failed to establish a new connection: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 719, in urlopen
    retries = retries.increment(
  File "/usr/lib/python3/dist-packages/urllib3/util/retry.py", line 436, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='api.desktoppr.co', port=443): Max retries exceeded with url: /1/wallpapers/random (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f200577d340>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/variety/VarietyWindow.py", line 1156, in download_one_from
  File "/usr/lib/python3/dist-packages/variety/plugins/downloaders/DefaultDownloader.py", line 141, in download_one
  File "/usr/lib/python3/dist-packages/variety/plugins/builtin/downloaders/DesktopprDownloader.py", line 57, in fill_queue
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 643, in fetch_json
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 612, in request
  File "/usr/lib/python3/dist-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/usr/lib/python3/dist-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='api.desktoppr.co', port=443): Max retries exceeded with url: /1/wallpapers/random (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f200577d340>: Failed to establish a new connection: [Errno 111] Connection refused'))
INFO: 2022-12-07 21:57:07,017: get_throttling() 'Unsplash.com: parsing serverside options'
INFO: 2022-12-07 21:57:07,017: get_throttling() 'Unsplash.com serverside options: {'min_fill_queue_interval': 3600, 'min_download_interval': 1800}'
INFO: 2022-12-07 21:57:07,018: get_throttling() 'Unsplash.com: parsing serverside options'
INFO: 2022-12-07 21:57:07,018: get_throttling() 'Unsplash.com serverside options: {'min_fill_queue_interval': 3600, 'min_download_interval': 1800}'
INFO: 2022-12-07 21:57:07,018: download_one() 'Unsplash.com: Downloading an image, config: None'
INFO: 2022-12-07 21:57:07,018: download_one() 'Unsplash.com: Queue size: 0'
INFO: 2022-12-07 21:57:07,018: get_throttling() 'Unsplash.com: parsing serverside options'
INFO: 2022-12-07 21:57:07,018: get_throttling() 'Unsplash.com serverside options: {'min_fill_queue_interval': 3600, 'min_download_interval': 1800}'
INFO: 2022-12-07 21:57:07,019: download_one() 'Unsplash.com: Queue empty, but max_queue_fills_per_hour of 3 reached, will try again later'
INFO: 2022-12-07 21:57:08,020: get_throttling() 'Bing: parsing serverside options'
INFO: 2022-12-07 21:57:08,020: get_throttling() 'Could not parse Bing serverside options, using defaults None, None'
INFO: 2022-12-07 21:57:08,020: get_throttling() 'Bing: parsing serverside options'
INFO: 2022-12-07 21:57:08,020: get_throttling() 'Could not parse Bing serverside options, using defaults None, None'
INFO: 2022-12-07 21:57:08,020: download_one() 'Bing: Downloading an image, config: None'
INFO: 2022-12-07 21:57:08,021: download_one() 'Bing: Queue size: 3'
INFO: 2022-12-07 21:57:08,021: download_one() 'Bing: Queue populated with 3 URLs'
INFO: 2022-12-07 21:57:08,021: save_locally() 'Origin URL: https://www.bing.com/search?q=rovinj+croatia&form=hpcapt&filters=HpDate%3a%2220221130_0800%22'
INFO: 2022-12-07 21:57:08,021: save_locally() 'Image URL: https://www.bing.com/th?id=OHR.RovinjCroatia_EN-US9834093615_1920x1080.jpg&rf=LaDigue_1920x1080.jpg&pid=hp'
INFO: 2022-12-07 21:57:08,021: save_locally() 'Local path: /home/abhinavgorantla/.config/variety/Downloaded/Bing/OHR.RovinjCroatia_EN-US9834093615_1920x1080.jpg'
INFO: 2022-12-07 21:57:08,022: save_locally() 'File already exists, skip downloading'
INFO: 2022-12-07 21:57:09,024: get_throttling() 'NASA Astro Pic of the Day: parsing serverside options'
INFO: 2022-12-07 21:57:09,024: get_throttling() 'Could not parse NASA Astro Pic of the Day serverside options, using defaults None, None'
INFO: 2022-12-07 21:57:09,024: get_throttling() 'NASA Astro Pic of the Day: parsing serverside options'
INFO: 2022-12-07 21:57:09,024: get_throttling() 'Could not parse NASA Astro Pic of the Day serverside options, using defaults None, None'
INFO: 2022-12-07 21:57:09,025: download_one() 'NASA Astro Pic of the Day: Downloading an image, config: None'
INFO: 2022-12-07 21:57:09,025: download_one() 'NASA Astro Pic of the Day: Queue size: 729'
INFO: 2022-12-07 21:57:09,025: download_one() 'NASA Astro Pic of the Day: Queue populated with 729 URLs'
INFO: 2022-12-07 21:57:09,025: download_queue_item() 'APOD URL: http://apod.nasa.gov/apod/ap210904.html'
ERROR: 2022-12-07 21:57:14,613: download_one_from() 'Could not download wallpaper:'
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/urllib3/connection.py", line 159, in _new_conn
    conn = connection.create_connection(
  File "/usr/lib/python3/dist-packages/urllib3/util/connection.py", line 84, in create_connection
    raise err
  File "/usr/lib/python3/dist-packages/urllib3/util/connection.py", line 74, in create_connection
    sock.connect(sa)
OSError: [Errno 101] Network is unreachable

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 665, in urlopen
    httplib_response = self._make_request(
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 376, in _make_request
    self._validate_conn(conn)
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 996, in _validate_conn
    conn.connect()
  File "/usr/lib/python3/dist-packages/urllib3/connection.py", line 314, in connect
    conn = self._new_conn()
  File "/usr/lib/python3/dist-packages/urllib3/connection.py", line 171, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.VerifiedHTTPSConnection object at 0x7f200577fd90>: Failed to establish a new connection: [Errno 101] Network is unreachable

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 719, in urlopen
    retries = retries.increment(
  File "/usr/lib/python3/dist-packages/urllib3/util/retry.py", line 436, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='apod.nasa.gov', port=443): Max retries exceeded with url: /apod/ap210904.html (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f200577fd90>: Failed to establish a new connection: [Errno 101] Network is unreachable'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/variety/VarietyWindow.py", line 1156, in download_one_from
  File "/usr/lib/python3/dist-packages/variety/plugins/downloaders/DefaultDownloader.py", line 153, in download_one
  File "/usr/lib/python3/dist-packages/variety/plugins/builtin/downloaders/APODDownloader.py", line 78, in download_queue_item
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 647, in html_soup
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 635, in fetch
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 612, in request
  File "/usr/lib/python3/dist-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 668, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 668, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 239, in resolve_redirects
    resp = self.send(
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/usr/lib/python3/dist-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='apod.nasa.gov', port=443): Max retries exceeded with url: /apod/ap210904.html (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f200577fd90>: Failed to establish a new connection: [Errno 101] Network is unreachable'))
INFO: 2022-12-07 21:58:54,406: regular_change_thread() 'regular_change changes wallpaper'
INFO: 2022-12-07 21:58:54,407: set_wallpaper() 'Calling set_wallpaper with /home/abhinavgorantla/.config/variety/Downloaded/Bing/OHR.HeronGiving_EN-US9774285216_1920x1080.jpg'
INFO: 2022-12-07 21:58:54,408: prepare_thread() 'Prepared buffer contains 91 images'
INFO: 2022-12-07 21:58:54,411: do_set_wp() 'Calling do_set_wp with /home/abhinavgorantla/.config/variety/Downloaded/Bing/OHR.HeronGiving_EN-US9774285216_1920x1080.jpg, time: 1670430534.411121'
INFO: 2022-12-07 21:58:54,437: update_indicator() 'Setting file info to: /home/abhinavgorantla/.config/variety/Downloaded/Bing/OHR.HeronGiving_EN-US9774285216_1920x1080.jpg'
INFO: 2022-12-07 21:58:54,443: list_files() 'More than 1 files in the folders, stop listing'
INFO: 2022-12-07 21:58:56,409: trigger_download() 'Triggering download thread to check if download needed'
INFO: 2022-12-07 21:58:56,410: get_throttling() 'Chrome OS Wallpapers: parsing serverside options'
INFO: 2022-12-07 21:58:56,411: get_throttling() 'Could not parse Chrome OS Wallpapers serverside options, using defaults None, None'
INFO: 2022-12-07 21:58:56,411: get_throttling() 'Chrome OS Wallpapers: parsing serverside options'
INFO: 2022-12-07 21:58:56,411: get_throttling() 'Could not parse Chrome OS Wallpapers serverside options, using defaults None, None'
INFO: 2022-12-07 21:58:56,411: download_one() 'Chrome OS Wallpapers: Downloading an image, config: None'
INFO: 2022-12-07 21:58:56,411: download_one() 'Chrome OS Wallpapers: Queue size: 0'
INFO: 2022-12-07 21:58:56,412: get_throttling() 'Chrome OS Wallpapers: parsing serverside options'
INFO: 2022-12-07 21:58:56,412: get_throttling() 'Could not parse Chrome OS Wallpapers serverside options, using defaults None, None'
INFO: 2022-12-07 21:58:56,412: trigger_download() 'Triggering download thread to check if download needed'
INFO: 2022-12-07 21:58:56,412: download_one() 'Chrome OS Wallpapers: Filling queue'
ERROR: 2022-12-07 21:58:58,323: download_one_from() 'Could not download wallpaper:'
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/variety/VarietyWindow.py", line 1156, in download_one_from
  File "/usr/lib/python3/dist-packages/variety/plugins/downloaders/DefaultDownloader.py", line 141, in download_one
  File "/usr/lib/python3/dist-packages/variety/plugins/builtin/downloaders/ChromeOSWallpapersDownloader.py", line 54, in fill_queue
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 643, in fetch_json
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 622, in request
  File "/usr/lib/python3/dist-packages/requests/models.py", line 940, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://storage.googleapis.com/chromeos-wallpaper-public/manifest_en.json
INFO: 2022-12-07 21:58:59,327: get_throttling() 'Desktoppr.co: parsing serverside options'
INFO: 2022-12-07 21:58:59,328: get_throttling() 'Could not parse Desktoppr.co serverside options, using defaults None, None'
INFO: 2022-12-07 21:58:59,328: get_throttling() 'Desktoppr.co: parsing serverside options'
INFO: 2022-12-07 21:58:59,328: get_throttling() 'Could not parse Desktoppr.co serverside options, using defaults None, None'
INFO: 2022-12-07 21:58:59,328: download_one() 'Desktoppr.co: Downloading an image, config: None'
INFO: 2022-12-07 21:58:59,329: download_one() 'Desktoppr.co: Queue size: 0'
INFO: 2022-12-07 21:58:59,329: get_throttling() 'Desktoppr.co: parsing serverside options'
INFO: 2022-12-07 21:58:59,329: get_throttling() 'Could not parse Desktoppr.co serverside options, using defaults None, None'
INFO: 2022-12-07 21:58:59,329: download_one() 'Desktoppr.co: Filling queue'
ERROR: 2022-12-07 21:58:59,609: download_one_from() 'Could not download wallpaper:'
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/urllib3/connection.py", line 159, in _new_conn
    conn = connection.create_connection(
  File "/usr/lib/python3/dist-packages/urllib3/util/connection.py", line 84, in create_connection
    raise err
  File "/usr/lib/python3/dist-packages/urllib3/util/connection.py", line 74, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 665, in urlopen
    httplib_response = self._make_request(
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 376, in _make_request
    self._validate_conn(conn)
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 996, in _validate_conn
    conn.connect()
  File "/usr/lib/python3/dist-packages/urllib3/connection.py", line 314, in connect
    conn = self._new_conn()
  File "/usr/lib/python3/dist-packages/urllib3/connection.py", line 171, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.VerifiedHTTPSConnection object at 0x7f200577b4c0>: Failed to establish a new connection: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 719, in urlopen
    retries = retries.increment(
  File "/usr/lib/python3/dist-packages/urllib3/util/retry.py", line 436, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='api.desktoppr.co', port=443): Max retries exceeded with url: /1/wallpapers/random (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f200577b4c0>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/variety/VarietyWindow.py", line 1156, in download_one_from
  File "/usr/lib/python3/dist-packages/variety/plugins/downloaders/DefaultDownloader.py", line 141, in download_one
  File "/usr/lib/python3/dist-packages/variety/plugins/builtin/downloaders/DesktopprDownloader.py", line 57, in fill_queue
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 643, in fetch_json
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 612, in request
  File "/usr/lib/python3/dist-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/usr/lib/python3/dist-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='api.desktoppr.co', port=443): Max retries exceeded with url: /1/wallpapers/random (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f200577b4c0>: Failed to establish a new connection: [Errno 111] Connection refused'))
INFO: 2022-12-07 21:59:00,612: get_throttling() 'Unsplash.com: parsing serverside options'
INFO: 2022-12-07 21:59:00,612: get_throttling() 'Unsplash.com serverside options: {'min_fill_queue_interval': 3600, 'min_download_interval': 1800}'
INFO: 2022-12-07 21:59:00,612: get_throttling() 'Unsplash.com: parsing serverside options'
INFO: 2022-12-07 21:59:00,612: get_throttling() 'Unsplash.com serverside options: {'min_fill_queue_interval': 3600, 'min_download_interval': 1800}'
INFO: 2022-12-07 21:59:00,612: download_one() 'Unsplash.com: Downloading an image, config: None'
INFO: 2022-12-07 21:59:00,613: download_one() 'Unsplash.com: Queue size: 0'
INFO: 2022-12-07 21:59:00,613: get_throttling() 'Unsplash.com: parsing serverside options'
INFO: 2022-12-07 21:59:00,613: get_throttling() 'Unsplash.com serverside options: {'min_fill_queue_interval': 3600, 'min_download_interval': 1800}'
INFO: 2022-12-07 21:59:00,613: download_one() 'Unsplash.com: Queue empty, but max_queue_fills_per_hour of 3 reached, will try again later'
INFO: 2022-12-07 21:59:01,615: get_throttling() 'Bing: parsing serverside options'
INFO: 2022-12-07 21:59:01,615: get_throttling() 'Could not parse Bing serverside options, using defaults None, None'
INFO: 2022-12-07 21:59:01,615: get_throttling() 'Bing: parsing serverside options'
INFO: 2022-12-07 21:59:01,616: get_throttling() 'Could not parse Bing serverside options, using defaults None, None'
INFO: 2022-12-07 21:59:01,616: download_one() 'Bing: Downloading an image, config: None'
INFO: 2022-12-07 21:59:01,616: download_one() 'Bing: Queue size: 2'
INFO: 2022-12-07 21:59:01,616: download_one() 'Bing: Queue populated with 2 URLs'
INFO: 2022-12-07 21:59:01,617: save_locally() 'Origin URL: https://www.bing.com/search?q=Pearl+Harbor+Remembrance+Day&form=hpcapt&filters=HpDate%3a%2220221207_0800%22'
INFO: 2022-12-07 21:59:01,617: save_locally() 'Image URL: https://www.bing.com/th?id=OHR.KaneoheHI_EN-US1621373073_1920x1080.jpg&rf=LaDigue_1920x1080.jpg&pid=hp'
INFO: 2022-12-07 21:59:01,617: save_locally() 'Local path: /home/abhinavgorantla/.config/variety/Downloaded/Bing/OHR.KaneoheHI_EN-US1621373073_1920x1080.jpg'
INFO: 2022-12-07 21:59:07,096: save_locally() 'Download complete'
INFO: 2022-12-07 21:59:07,096: update_indicator() 'Setting file info to: /home/abhinavgorantla/.config/variety/Downloaded/Bing/OHR.HeronGiving_EN-US9774285216_1920x1080.jpg'
INFO: 2022-12-07 21:59:07,102: list_files() 'More than 1 files in the folders, stop listing'
INFO: 2022-12-07 21:59:07,104: download_one_from() 'Adding downloaded file /home/abhinavgorantla/.config/variety/Downloaded/Bing/OHR.KaneoheHI_EN-US1621373073_1920x1080.jpg to unseen_downloads'
INFO: 2022-12-07 21:59:08,109: get_throttling() 'Bing: parsing serverside options'
INFO: 2022-12-07 21:59:08,109: get_throttling() 'Could not parse Bing serverside options, using defaults None, None'
INFO: 2022-12-07 21:59:08,109: get_throttling() 'Bing: parsing serverside options'
INFO: 2022-12-07 21:59:08,109: get_throttling() 'Could not parse Bing serverside options, using defaults None, None'
INFO: 2022-12-07 21:59:08,109: download_one() 'Bing: Downloading an image, config: None'
INFO: 2022-12-07 21:59:08,110: download_one() 'Bing: Queue size: 1'
INFO: 2022-12-07 21:59:08,110: download_one() 'Bing: Queue populated with 1 URLs'
INFO: 2022-12-07 21:59:08,110: save_locally() 'Origin URL: https://www.bing.com/search?q=Mt.+Kilimanjaro&form=hpcapt&filters=HpDate%3a%2220221204_0800%22'
INFO: 2022-12-07 21:59:08,110: save_locally() 'Image URL: https://www.bing.com/th?id=OHR.KilimanjaroElephants_EN-US1249382486_1920x1080.jpg&rf=LaDigue_1920x1080.jpg&pid=hp'
INFO: 2022-12-07 21:59:08,110: save_locally() 'Local path: /home/abhinavgorantla/.config/variety/Downloaded/Bing/OHR.KilimanjaroElephants_EN-US1249382486_1920x1080.jpg'
INFO: 2022-12-07 21:59:08,111: save_locally() 'File already exists, skip downloading'
INFO: 2022-12-07 21:59:09,112: get_throttling() 'NASA Astro Pic of the Day: parsing serverside options'
INFO: 2022-12-07 21:59:09,112: get_throttling() 'Could not parse NASA Astro Pic of the Day serverside options, using defaults None, None'
INFO: 2022-12-07 21:59:09,112: get_throttling() 'NASA Astro Pic of the Day: parsing serverside options'
INFO: 2022-12-07 21:59:09,112: get_throttling() 'Could not parse NASA Astro Pic of the Day serverside options, using defaults None, None'
INFO: 2022-12-07 21:59:09,112: download_one() 'NASA Astro Pic of the Day: Downloading an image, config: None'
INFO: 2022-12-07 21:59:09,113: download_one() 'NASA Astro Pic of the Day: Queue size: 728'
INFO: 2022-12-07 21:59:09,113: download_one() 'NASA Astro Pic of the Day: Queue populated with 728 URLs'
INFO: 2022-12-07 21:59:09,113: download_queue_item() 'APOD URL: http://apod.nasa.gov/apod/ap211012.html'
INFO: 2022-12-07 21:59:11,726: download_queue_item() 'Image URL: http://apod.nasa.gov/apod/image/2110/FireballAlberta_Qin_5568.jpg'
INFO: 2022-12-07 21:59:11,726: save_locally() 'Origin URL: http://apod.nasa.gov/apod/ap211012.html'
INFO: 2022-12-07 21:59:11,726: save_locally() 'Image URL: http://apod.nasa.gov/apod/image/2110/FireballAlberta_Qin_5568.jpg'
INFO: 2022-12-07 21:59:11,727: save_locally() 'Local path: /home/abhinavgorantla/.config/variety/Downloaded/nasa_apod/FireballAlberta_Qin_5568.jpg'
INFO: 2022-12-07 21:59:17,588: save_locally() 'Download failed from image URL: http://apod.nasa.gov/apod/image/2110/FireballAlberta_Qin_5568.jpg (source location: http://apod.nasa.gov/apod/) '
ERROR: 2022-12-07 21:59:17,589: safe_unlink() 'Could not delete /home/abhinavgorantla/.config/variety/Downloaded/nasa_apod/FireballAlberta_Qin_5568.jpg.partial, ignoring'
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 376, in _make_request
    self._validate_conn(conn)
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 996, in _validate_conn
    conn.connect()
  File "/usr/lib/python3/dist-packages/urllib3/connection.py", line 366, in connect
    self.sock = ssl_wrap_socket(
  File "/usr/lib/python3/dist-packages/urllib3/util/ssl_.py", line 370, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "/usr/lib/python3.8/ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
  File "/usr/lib/python3.8/ssl.py", line 1040, in _create
    self.do_handshake()
  File "/usr/lib/python3.8/ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
socket.timeout: _ssl.c:1114: The handshake operation timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 719, in urlopen
    retries = retries.increment(
  File "/usr/lib/python3/dist-packages/urllib3/util/retry.py", line 400, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/usr/lib/python3/dist-packages/six.py", line 703, in reraise
    raise value
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 665, in urlopen
    httplib_response = self._make_request(
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 379, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 330, in _raise_timeout
    raise ReadTimeoutError(
urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='apod.nasa.gov', port=443): Read timed out. (read timeout=5)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/variety/plugins/downloaders/DefaultDownloader.py", line 233, in save_locally
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 612, in request
  File "/usr/lib/python3/dist-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 668, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 668, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 239, in resolve_redirects
    resp = self.send(
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/usr/lib/python3/dist-packages/requests/adapters.py", line 529, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='apod.nasa.gov', port=443): Read timed out. (read timeout=5)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 880, in safe_unlink
FileNotFoundError: [Errno 2] No such file or directory: '/home/abhinavgorantla/.config/variety/Downloaded/nasa_apod/FireballAlberta_Qin_5568.jpg.partial'
ERROR: 2022-12-07 21:59:17,591: download_one_from() 'Could not download wallpaper:'
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 376, in _make_request
    self._validate_conn(conn)
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 996, in _validate_conn
    conn.connect()
  File "/usr/lib/python3/dist-packages/urllib3/connection.py", line 366, in connect
    self.sock = ssl_wrap_socket(
  File "/usr/lib/python3/dist-packages/urllib3/util/ssl_.py", line 370, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "/usr/lib/python3.8/ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
  File "/usr/lib/python3.8/ssl.py", line 1040, in _create
    self.do_handshake()
  File "/usr/lib/python3.8/ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
socket.timeout: _ssl.c:1114: The handshake operation timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 719, in urlopen
    retries = retries.increment(
  File "/usr/lib/python3/dist-packages/urllib3/util/retry.py", line 400, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/usr/lib/python3/dist-packages/six.py", line 703, in reraise
    raise value
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 665, in urlopen
    httplib_response = self._make_request(
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 379, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 330, in _raise_timeout
    raise ReadTimeoutError(
urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='apod.nasa.gov', port=443): Read timed out. (read timeout=5)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/variety/VarietyWindow.py", line 1156, in download_one_from
  File "/usr/lib/python3/dist-packages/variety/plugins/downloaders/DefaultDownloader.py", line 153, in download_one
  File "/usr/lib/python3/dist-packages/variety/plugins/builtin/downloaders/APODDownloader.py", line 89, in download_queue_item
  File "/usr/lib/python3/dist-packages/variety/plugins/downloaders/DefaultDownloader.py", line 244, in save_locally
  File "/usr/lib/python3/dist-packages/variety/plugins/downloaders/DefaultDownloader.py", line 233, in save_locally
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 612, in request
  File "/usr/lib/python3/dist-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 668, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 668, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 239, in resolve_redirects
    resp = self.send(
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/usr/lib/python3/dist-packages/requests/adapters.py", line 529, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='apod.nasa.gov', port=443): Read timed out. (read timeout=5)
INFO: 2022-12-07 22:02:18,596: get_throttling() 'Chrome OS Wallpapers: parsing serverside options'
INFO: 2022-12-07 22:02:18,596: get_throttling() 'Could not parse Chrome OS Wallpapers serverside options, using defaults None, None'
INFO: 2022-12-07 22:02:18,596: get_throttling() 'Chrome OS Wallpapers: parsing serverside options'
INFO: 2022-12-07 22:02:18,596: get_throttling() 'Could not parse Chrome OS Wallpapers serverside options, using defaults None, None'
INFO: 2022-12-07 22:02:18,597: download_one() 'Chrome OS Wallpapers: Downloading an image, config: None'
INFO: 2022-12-07 22:02:18,597: download_one() 'Chrome OS Wallpapers: Queue size: 0'
INFO: 2022-12-07 22:02:18,597: get_throttling() 'Chrome OS Wallpapers: parsing serverside options'
INFO: 2022-12-07 22:02:18,597: get_throttling() 'Could not parse Chrome OS Wallpapers serverside options, using defaults None, None'
INFO: 2022-12-07 22:02:18,597: download_one() 'Chrome OS Wallpapers: Filling queue'
ERROR: 2022-12-07 22:02:20,409: download_one_from() 'Could not download wallpaper:'
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/variety/VarietyWindow.py", line 1156, in download_one_from
  File "/usr/lib/python3/dist-packages/variety/plugins/downloaders/DefaultDownloader.py", line 141, in download_one
  File "/usr/lib/python3/dist-packages/variety/plugins/builtin/downloaders/ChromeOSWallpapersDownloader.py", line 54, in fill_queue
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 643, in fetch_json
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 622, in request
  File "/usr/lib/python3/dist-packages/requests/models.py", line 940, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://storage.googleapis.com/chromeos-wallpaper-public/manifest_en.json
INFO: 2022-12-07 22:02:21,412: get_throttling() 'Desktoppr.co: parsing serverside options'
INFO: 2022-12-07 22:02:21,412: get_throttling() 'Could not parse Desktoppr.co serverside options, using defaults None, None'
INFO: 2022-12-07 22:02:21,412: get_throttling() 'Desktoppr.co: parsing serverside options'
INFO: 2022-12-07 22:02:21,413: get_throttling() 'Could not parse Desktoppr.co serverside options, using defaults None, None'
INFO: 2022-12-07 22:02:21,413: download_one() 'Desktoppr.co: Downloading an image, config: None'
INFO: 2022-12-07 22:02:21,413: download_one() 'Desktoppr.co: Queue size: 0'
INFO: 2022-12-07 22:02:21,413: get_throttling() 'Desktoppr.co: parsing serverside options'
INFO: 2022-12-07 22:02:21,413: get_throttling() 'Could not parse Desktoppr.co serverside options, using defaults None, None'
INFO: 2022-12-07 22:02:21,414: download_one() 'Desktoppr.co: Filling queue'
ERROR: 2022-12-07 22:02:21,813: download_one_from() 'Could not download wallpaper:'
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/urllib3/connection.py", line 159, in _new_conn
    conn = connection.create_connection(
  File "/usr/lib/python3/dist-packages/urllib3/util/connection.py", line 84, in create_connection
    raise err
  File "/usr/lib/python3/dist-packages/urllib3/util/connection.py", line 74, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 665, in urlopen
    httplib_response = self._make_request(
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 376, in _make_request
    self._validate_conn(conn)
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 996, in _validate_conn
    conn.connect()
  File "/usr/lib/python3/dist-packages/urllib3/connection.py", line 314, in connect
    conn = self._new_conn()
  File "/usr/lib/python3/dist-packages/urllib3/connection.py", line 171, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.VerifiedHTTPSConnection object at 0x7f200578f940>: Failed to establish a new connection: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 719, in urlopen
    retries = retries.increment(
  File "/usr/lib/python3/dist-packages/urllib3/util/retry.py", line 436, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='api.desktoppr.co', port=443): Max retries exceeded with url: /1/wallpapers/random (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f200578f940>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/variety/VarietyWindow.py", line 1156, in download_one_from
  File "/usr/lib/python3/dist-packages/variety/plugins/downloaders/DefaultDownloader.py", line 141, in download_one
  File "/usr/lib/python3/dist-packages/variety/plugins/builtin/downloaders/DesktopprDownloader.py", line 57, in fill_queue
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 643, in fetch_json
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 612, in request
  File "/usr/lib/python3/dist-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/usr/lib/python3/dist-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='api.desktoppr.co', port=443): Max retries exceeded with url: /1/wallpapers/random (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f200578f940>: Failed to establish a new connection: [Errno 111] Connection refused'))
INFO: 2022-12-07 22:02:22,817: get_throttling() 'Unsplash.com: parsing serverside options'
INFO: 2022-12-07 22:02:22,817: get_throttling() 'Unsplash.com serverside options: {'min_fill_queue_interval': 3600, 'min_download_interval': 1800}'
INFO: 2022-12-07 22:02:22,818: get_throttling() 'Unsplash.com: parsing serverside options'
INFO: 2022-12-07 22:02:22,818: get_throttling() 'Unsplash.com serverside options: {'min_fill_queue_interval': 3600, 'min_download_interval': 1800}'
INFO: 2022-12-07 22:02:22,818: download_one() 'Unsplash.com: Downloading an image, config: None'
INFO: 2022-12-07 22:02:22,819: download_one() 'Unsplash.com: Queue size: 0'
INFO: 2022-12-07 22:02:22,819: get_throttling() 'Unsplash.com: parsing serverside options'
INFO: 2022-12-07 22:02:22,819: get_throttling() 'Unsplash.com serverside options: {'min_fill_queue_interval': 3600, 'min_download_interval': 1800}'
INFO: 2022-12-07 22:02:22,819: download_one() 'Unsplash.com: Queue empty, but max_queue_fills_per_hour of 3 reached, will try again later'
INFO: 2022-12-07 22:02:23,822: get_throttling() 'Bing: parsing serverside options'
INFO: 2022-12-07 22:02:23,822: get_throttling() 'Could not parse Bing serverside options, using defaults None, None'
INFO: 2022-12-07 22:02:23,822: get_throttling() 'Bing: parsing serverside options'
INFO: 2022-12-07 22:02:23,822: get_throttling() 'Could not parse Bing serverside options, using defaults None, None'
INFO: 2022-12-07 22:02:23,822: download_one() 'Bing: Downloading an image, config: None'
INFO: 2022-12-07 22:02:23,823: download_one() 'Bing: Queue size: 0'
INFO: 2022-12-07 22:02:23,823: get_throttling() 'Bing: parsing serverside options'
INFO: 2022-12-07 22:02:23,823: get_throttling() 'Could not parse Bing serverside options, using defaults None, None'
INFO: 2022-12-07 22:02:23,823: download_one() 'Bing: Filling queue'
INFO: 2022-12-07 22:02:24,305: download_one() 'Bing: Queue populated with 7 URLs'
INFO: 2022-12-07 22:02:24,305: save_locally() 'Origin URL: https://www.bing.com/search?q=Mt.+Kilimanjaro&form=hpcapt&filters=HpDate%3a%2220221204_0800%22'
INFO: 2022-12-07 22:02:24,305: save_locally() 'Image URL: https://www.bing.com/th?id=OHR.KilimanjaroElephants_EN-US1249382486_1920x1080.jpg&rf=LaDigue_1920x1080.jpg&pid=hp'
INFO: 2022-12-07 22:02:24,305: save_locally() 'Local path: /home/abhinavgorantla/.config/variety/Downloaded/Bing/OHR.KilimanjaroElephants_EN-US1249382486_1920x1080.jpg'
INFO: 2022-12-07 22:02:24,306: save_locally() 'File already exists, skip downloading'
INFO: 2022-12-07 22:02:25,308: get_throttling() 'NASA Astro Pic of the Day: parsing serverside options'
INFO: 2022-12-07 22:02:25,308: get_throttling() 'Could not parse NASA Astro Pic of the Day serverside options, using defaults None, None'
INFO: 2022-12-07 22:02:25,308: get_throttling() 'NASA Astro Pic of the Day: parsing serverside options'
INFO: 2022-12-07 22:02:25,308: get_throttling() 'Could not parse NASA Astro Pic of the Day serverside options, using defaults None, None'
INFO: 2022-12-07 22:02:25,308: download_one() 'NASA Astro Pic of the Day: Downloading an image, config: None'
INFO: 2022-12-07 22:02:25,309: download_one() 'NASA Astro Pic of the Day: Queue size: 727'
INFO: 2022-12-07 22:02:25,309: download_one() 'NASA Astro Pic of the Day: Queue populated with 727 URLs'
INFO: 2022-12-07 22:02:25,309: download_queue_item() 'APOD URL: http://apod.nasa.gov/apod/ap210703.html'
ERROR: 2022-12-07 22:02:31,231: download_one_from() 'Could not download wallpaper:'
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 376, in _make_request
    self._validate_conn(conn)
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 996, in _validate_conn
    conn.connect()
  File "/usr/lib/python3/dist-packages/urllib3/connection.py", line 366, in connect
    self.sock = ssl_wrap_socket(
  File "/usr/lib/python3/dist-packages/urllib3/util/ssl_.py", line 370, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "/usr/lib/python3.8/ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
  File "/usr/lib/python3.8/ssl.py", line 1040, in _create
    self.do_handshake()
  File "/usr/lib/python3.8/ssl.py", line 1309, in do_handshake
    self._sslobj.do_handshake()
socket.timeout: _ssl.c:1114: The handshake operation timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 719, in urlopen
    retries = retries.increment(
  File "/usr/lib/python3/dist-packages/urllib3/util/retry.py", line 400, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/usr/lib/python3/dist-packages/six.py", line 703, in reraise
    raise value
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 665, in urlopen
    httplib_response = self._make_request(
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 379, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 330, in _raise_timeout
    raise ReadTimeoutError(
urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='apod.nasa.gov', port=443): Read timed out. (read timeout=5)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/variety/VarietyWindow.py", line 1156, in download_one_from
  File "/usr/lib/python3/dist-packages/variety/plugins/downloaders/DefaultDownloader.py", line 153, in download_one
  File "/usr/lib/python3/dist-packages/variety/plugins/builtin/downloaders/APODDownloader.py", line 78, in download_queue_item
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 647, in html_soup
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 635, in fetch
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 612, in request
  File "/usr/lib/python3/dist-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 668, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 668, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 239, in resolve_redirects
    resp = self.send(
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/usr/lib/python3/dist-packages/requests/adapters.py", line 529, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='apod.nasa.gov', port=443): Read timed out. (read timeout=5)
INFO: 2022-12-07 22:03:54,543: regular_change_thread() 'regular_change changes wallpaper'
INFO: 2022-12-07 22:03:54,544: set_wallpaper() 'Calling set_wallpaper with /home/abhinavgorantla/.config/variety/Downloaded/Earth View/Aktogay District, Kazakhstan (ID-5207).jpg'
INFO: 2022-12-07 22:03:54,544: prepare_thread() 'Prepared buffer contains 91 images'
INFO: 2022-12-07 22:03:54,547: do_set_wp() 'Calling do_set_wp with /home/abhinavgorantla/.config/variety/Downloaded/Earth View/Aktogay District, Kazakhstan (ID-5207).jpg, time: 1670430834.5474427'
INFO: 2022-12-07 22:03:54,574: update_indicator() 'Setting file info to: /home/abhinavgorantla/.config/variety/Downloaded/Earth View/Aktogay District, Kazakhstan (ID-5207).jpg'
INFO: 2022-12-07 22:03:54,586: list_files() 'More than 1 files in the folders, stop listing'
INFO: 2022-12-07 22:03:56,546: trigger_download() 'Triggering download thread to check if download needed'
INFO: 2022-12-07 22:03:56,547: get_throttling() 'Chrome OS Wallpapers: parsing serverside options'
INFO: 2022-12-07 22:03:56,547: get_throttling() 'Could not parse Chrome OS Wallpapers serverside options, using defaults None, None'
INFO: 2022-12-07 22:03:56,547: get_throttling() 'Chrome OS Wallpapers: parsing serverside options'
INFO: 2022-12-07 22:03:56,548: get_throttling() 'Could not parse Chrome OS Wallpapers serverside options, using defaults None, None'
INFO: 2022-12-07 22:03:56,548: download_one() 'Chrome OS Wallpapers: Downloading an image, config: None'
INFO: 2022-12-07 22:03:56,548: download_one() 'Chrome OS Wallpapers: Queue size: 0'
INFO: 2022-12-07 22:03:56,548: get_throttling() 'Chrome OS Wallpapers: parsing serverside options'
INFO: 2022-12-07 22:03:56,548: get_throttling() 'Could not parse Chrome OS Wallpapers serverside options, using defaults None, None'
INFO: 2022-12-07 22:03:56,548: download_one() 'Chrome OS Wallpapers: Filling queue'
INFO: 2022-12-07 22:03:56,549: trigger_download() 'Triggering download thread to check if download needed'
ERROR: 2022-12-07 22:03:58,166: download_one_from() 'Could not download wallpaper:'
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/variety/VarietyWindow.py", line 1156, in download_one_from
  File "/usr/lib/python3/dist-packages/variety/plugins/downloaders/DefaultDownloader.py", line 141, in download_one
  File "/usr/lib/python3/dist-packages/variety/plugins/builtin/downloaders/ChromeOSWallpapersDownloader.py", line 54, in fill_queue
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 643, in fetch_json
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 622, in request
  File "/usr/lib/python3/dist-packages/requests/models.py", line 940, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://storage.googleapis.com/chromeos-wallpaper-public/manifest_en.json
INFO: 2022-12-07 22:03:59,171: get_throttling() 'Desktoppr.co: parsing serverside options'
INFO: 2022-12-07 22:03:59,171: get_throttling() 'Could not parse Desktoppr.co serverside options, using defaults None, None'
INFO: 2022-12-07 22:03:59,171: get_throttling() 'Desktoppr.co: parsing serverside options'
INFO: 2022-12-07 22:03:59,171: get_throttling() 'Could not parse Desktoppr.co serverside options, using defaults None, None'
INFO: 2022-12-07 22:03:59,171: download_one() 'Desktoppr.co: Downloading an image, config: None'
INFO: 2022-12-07 22:03:59,172: download_one() 'Desktoppr.co: Queue size: 0'
INFO: 2022-12-07 22:03:59,172: get_throttling() 'Desktoppr.co: parsing serverside options'
INFO: 2022-12-07 22:03:59,172: get_throttling() 'Could not parse Desktoppr.co serverside options, using defaults None, None'
INFO: 2022-12-07 22:03:59,172: download_one() 'Desktoppr.co: Filling queue'
ERROR: 2022-12-07 22:03:59,517: download_one_from() 'Could not download wallpaper:'
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/urllib3/connection.py", line 159, in _new_conn
    conn = connection.create_connection(
  File "/usr/lib/python3/dist-packages/urllib3/util/connection.py", line 84, in create_connection
    raise err
  File "/usr/lib/python3/dist-packages/urllib3/util/connection.py", line 74, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 665, in urlopen
    httplib_response = self._make_request(
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 376, in _make_request
    self._validate_conn(conn)
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 996, in _validate_conn
    conn.connect()
  File "/usr/lib/python3/dist-packages/urllib3/connection.py", line 314, in connect
    conn = self._new_conn()
  File "/usr/lib/python3/dist-packages/urllib3/connection.py", line 171, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.VerifiedHTTPSConnection object at 0x7f200571c160>: Failed to establish a new connection: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
  File "/usr/lib/python3/dist-packages/urllib3/connectionpool.py", line 719, in urlopen
    retries = retries.increment(
  File "/usr/lib/python3/dist-packages/urllib3/util/retry.py", line 436, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='api.desktoppr.co', port=443): Max retries exceeded with url: /1/wallpapers/random (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f200571c160>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/variety/VarietyWindow.py", line 1156, in download_one_from
  File "/usr/lib/python3/dist-packages/variety/plugins/downloaders/DefaultDownloader.py", line 141, in download_one
  File "/usr/lib/python3/dist-packages/variety/plugins/builtin/downloaders/DesktopprDownloader.py", line 57, in fill_queue
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 643, in fetch_json
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 612, in request
  File "/usr/lib/python3/dist-packages/requests/api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "/usr/lib/python3/dist-packages/requests/sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "/usr/lib/python3/dist-packages/requests/adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='api.desktoppr.co', port=443): Max retries exceeded with url: /1/wallpapers/random (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f200571c160>: Failed to establish a new connection: [Errno 111] Connection refused'))
INFO: 2022-12-07 22:04:00,520: get_throttling() 'Unsplash.com: parsing serverside options'
INFO: 2022-12-07 22:04:00,520: get_throttling() 'Unsplash.com serverside options: {'min_fill_queue_interval': 3600, 'min_download_interval': 1800}'
INFO: 2022-12-07 22:04:00,520: get_throttling() 'Unsplash.com: parsing serverside options'
INFO: 2022-12-07 22:04:00,520: get_throttling() 'Unsplash.com serverside options: {'min_fill_queue_interval': 3600, 'min_download_interval': 1800}'
INFO: 2022-12-07 22:04:00,520: download_one() 'Unsplash.com: Downloading an image, config: None'
INFO: 2022-12-07 22:04:00,521: download_one() 'Unsplash.com: Queue size: 0'
INFO: 2022-12-07 22:04:00,521: get_throttling() 'Unsplash.com: parsing serverside options'
INFO: 2022-12-07 22:04:00,521: get_throttling() 'Unsplash.com serverside options: {'min_fill_queue_interval': 3600, 'min_download_interval': 1800}'
INFO: 2022-12-07 22:04:00,521: download_one() 'Unsplash.com: Queue empty, but max_queue_fills_per_hour of 3 reached, will try again later'
INFO: 2022-12-07 22:04:01,523: get_throttling() 'Bing: parsing serverside options'
INFO: 2022-12-07 22:04:01,523: get_throttling() 'Could not parse Bing serverside options, using defaults None, None'
INFO: 2022-12-07 22:04:01,523: get_throttling() 'Bing: parsing serverside options'
INFO: 2022-12-07 22:04:01,524: get_throttling() 'Could not parse Bing serverside options, using defaults None, None'
INFO: 2022-12-07 22:04:01,524: download_one() 'Bing: Downloading an image, config: None'
INFO: 2022-12-07 22:04:01,524: download_one() 'Bing: Queue size: 6'
INFO: 2022-12-07 22:04:01,524: download_one() 'Bing: Queue populated with 6 URLs'
INFO: 2022-12-07 22:04:01,524: save_locally() 'Origin URL: https://www.bing.com/search?q=Pearl+Harbor+Remembrance+Day&form=hpcapt&filters=HpDate%3a%2220221207_0800%22'
INFO: 2022-12-07 22:04:01,525: save_locally() 'Image URL: https://www.bing.com/th?id=OHR.KaneoheHI_EN-US1621373073_1920x1080.jpg&rf=LaDigue_1920x1080.jpg&pid=hp'
INFO: 2022-12-07 22:04:01,525: save_locally() 'Local path: /home/abhinavgorantla/.config/variety/Downloaded/Bing/OHR.KaneoheHI_EN-US1621373073_1920x1080.jpg'
INFO: 2022-12-07 22:04:01,525: save_locally() 'File already exists, skip downloading'
INFO: 2022-12-07 22:04:02,527: get_throttling() 'NASA Astro Pic of the Day: parsing serverside options'
INFO: 2022-12-07 22:04:02,528: get_throttling() 'Could not parse NASA Astro Pic of the Day serverside options, using defaults None, None'
INFO: 2022-12-07 22:04:02,528: get_throttling() 'NASA Astro Pic of the Day: parsing serverside options'
INFO: 2022-12-07 22:04:02,528: get_throttling() 'Could not parse NASA Astro Pic of the Day serverside options, using defaults None, None'
INFO: 2022-12-07 22:04:02,528: download_one() 'NASA Astro Pic of the Day: Downloading an image, config: None'
INFO: 2022-12-07 22:04:02,529: download_one() 'NASA Astro Pic of the Day: Queue size: 726'
INFO: 2022-12-07 22:04:02,529: download_one() 'NASA Astro Pic of the Day: Queue populated with 726 URLs'
INFO: 2022-12-07 22:04:02,529: download_queue_item() 'APOD URL: http://apod.nasa.gov/apod/ap211202.html'
INFO: 2022-12-07 22:04:05,308: download_queue_item() 'Image URL: http://apod.nasa.gov/apod/image/2112/NGC6822LRGB-1.jpg'
INFO: 2022-12-07 22:04:05,308: save_locally() 'Origin URL: http://apod.nasa.gov/apod/ap211202.html'
INFO: 2022-12-07 22:04:05,308: save_locally() 'Image URL: http://apod.nasa.gov/apod/image/2112/NGC6822LRGB-1.jpg'
INFO: 2022-12-07 22:04:05,308: save_locally() 'Local path: /home/abhinavgorantla/.config/variety/Downloaded/nasa_apod/NGC6822LRGB-1.jpg'
INFO: 2022-12-07 22:04:34,491: save_locally() 'Download failed from image URL: http://apod.nasa.gov/apod/image/2112/NGC6822LRGB-1.jpg (source location: http://apod.nasa.gov/apod/) '
ERROR: 2022-12-07 22:04:34,491: download_one_from() 'Could not download wallpaper:'
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/urllib3/response.py", line 425, in _error_catcher
    yield
  File "/usr/lib/python3/dist-packages/urllib3/response.py", line 507, in read
    data = self._fp.read(amt) if not fp_closed else b""
  File "/usr/lib/python3.8/http/client.py", line 459, in read
    n = self.readinto(b)
  File "/usr/lib/python3.8/http/client.py", line 503, in readinto
    n = self.fp.readinto(b)
  File "/usr/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/usr/lib/python3.8/ssl.py", line 1241, in recv_into
    return self.read(nbytes, buffer)
  File "/usr/lib/python3.8/ssl.py", line 1099, in read
    return self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/requests/models.py", line 750, in generate
    for chunk in self.raw.stream(chunk_size, decode_content=True):
  File "/usr/lib/python3/dist-packages/urllib3/response.py", line 564, in stream
    data = self.read(amt=amt, decode_content=decode_content)
  File "/usr/lib/python3/dist-packages/urllib3/response.py", line 529, in read
    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/lib/python3/dist-packages/urllib3/response.py", line 430, in _error_catcher
    raise ReadTimeoutError(self._pool, None, "Read timed out.")
urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='apod.nasa.gov', port=443): Read timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/variety/VarietyWindow.py", line 1156, in download_one_from
  File "/usr/lib/python3/dist-packages/variety/plugins/downloaders/DefaultDownloader.py", line 153, in download_one
  File "/usr/lib/python3/dist-packages/variety/plugins/builtin/downloaders/APODDownloader.py", line 89, in download_queue_item
  File "/usr/lib/python3/dist-packages/variety/plugins/downloaders/DefaultDownloader.py", line 244, in save_locally
  File "/usr/lib/python3/dist-packages/variety/plugins/downloaders/DefaultDownloader.py", line 237, in save_locally
  File "/usr/lib/python3/dist-packages/variety/Util.py", line 630, in request_write_to
  File "/usr/lib/python3/dist-packages/requests/models.py", line 757, in generate
    raise ConnectionError(e)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='apod.nasa.gov', port=443): Read timed out.
INFO: 2022-12-07 22:04:35,497: get_throttling() 'Earth View: parsing serverside options'
INFO: 2022-12-07 22:04:35,498: get_throttling() 'Could not parse Earth View serverside options, using defaults 20, None'
INFO: 2022-12-07 22:04:35,498: get_throttling() 'Earth View: parsing serverside options'
INFO: 2022-12-07 22:04:35,498: get_throttling() 'Could not parse Earth View serverside options, using defaults 20, None'
INFO: 2022-12-07 22:04:35,498: download_one() 'Earth View: Downloading an image, config: None'
INFO: 2022-12-07 22:04:35,498: download_one() 'Earth View: Queue size: 0'
INFO: 2022-12-07 22:04:35,498: get_throttling() 'Earth View: parsing serverside options'
INFO: 2022-12-07 22:04:35,498: get_throttling() 'Could not parse Earth View serverside options, using defaults 20, None'
INFO: 2022-12-07 22:04:35,499: download_one() 'Earth View: Filling queue'
INFO: 2022-12-07 22:04:36,431: download_one() 'Earth View: Queue populated with 1511 URLs'
INFO: 2022-12-07 22:04:36,432: save_locally() 'Origin URL: https://earthview.withgoogle.com/2121'
INFO: 2022-12-07 22:04:36,432: save_locally() 'Image URL: https://www.gstatic.com/prettyearth/assets/full/2121.jpg'
INFO: 2022-12-07 22:04:36,432: save_locally() 'Local path: /home/abhinavgorantla/.config/variety/Downloaded/Earth View/Plouescat, France (ID-2121).jpg'
INFO: 2022-12-07 22:04:37,392: save_locally() 'Download complete'
INFO: 2022-12-07 22:04:37,392: update_indicator() 'Setting file info to: /home/abhinavgorantla/.config/variety/Downloaded/Earth View/Aktogay District, Kazakhstan (ID-5207).jpg'
INFO: 2022-12-07 22:04:37,398: list_files() 'More than 1 files in the folders, stop listing'
INFO: 2022-12-07 22:04:37,399: download_one_from() 'Adding downloaded file /home/abhinavgorantla/.config/variety/Downloaded/Earth View/Plouescat, France (ID-2121).jpg to unseen_downloads'
